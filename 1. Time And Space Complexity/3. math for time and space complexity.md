# Big O Mathematical Laws & Formulas
## Complete Reference Guide

---

## ğŸ“ **Foundation Laws (à¦®à§‚à¦² à¦¨à¦¿à¦¯à¦¼à¦®)**

### **Law 1: Constant Elimination**
```
O(c Ã— f(n)) = O(f(n))    where c is constant
Examples:
O(5n) = O(n)
O(100) = O(1)
O(3nÂ² + 7) = O(nÂ²)
```

### **Law 2: Dominant Term Rule**
```
O(f(n) + g(n)) = O(max(f(n), g(n)))
Examples:
O(nÂ² + n) = O(nÂ²)
O(nÂ³ + nÂ² + n + 1) = O(nÂ³)
O(2â¿ + nÂ¹â°â°) = O(2â¿)
```

### **Law 3: Sequential Operations (Addition)**
```
Sequential: O(f(n)) + O(g(n)) = O(f(n) + g(n))
Examples:
Loop1: O(n) + Loop2: O(m) = O(n + m)
O(n) + O(log n) = O(n)
```

### **Law 4: Nested Operations (Multiplication)**
```
Nested: O(f(n)) Ã— O(g(n)) = O(f(n) Ã— g(n))
Examples:
Outer: O(n) Ã— Inner: O(m) = O(nm)
O(n) Ã— O(log n) = O(n log n)
```

---

## ğŸ§® **Complete Mathematical Series Collection**

### **Arithmetic Progressions (AP)**
```
General AP: a, a+d, a+2d, ..., a+(n-1)d

Sum of AP: S_n = n/2 Ã— [2a + (n-1)d] = n/2 Ã— (first + last)
Examples:
Î£(i=1 to n) i = n(n+1)/2                            â†’ O(nÂ²)
Î£(i=1 to n) (2i-1) = nÂ²                             â†’ O(nÂ²) [odd numbers]
Î£(i=1 to n) 2i = n(n+1)                             â†’ O(nÂ²) [even numbers]
Î£(i=a to b) i = (b-a+1)(a+b)/2                      â†’ O((b-a)Â²)
```

### **Geometric Progressions (GP)**
```
General GP: a, ar, arÂ², ..., ar^(n-1)

Sum of GP: S_n = a(r^n - 1)/(r - 1)    when r â‰  1
          S_n = na                      when r = 1

Examples:
Î£(i=0 to n) 2â± = 2â¿âºÂ¹ - 1                          â†’ O(2â¿)
Î£(i=0 to n) 3â± = (3â¿âºÂ¹ - 1)/2                      â†’ O(3â¿)
Î£(i=0 to n) râ± = (râ¿âºÂ¹ - 1)/(r-1)                  â†’ O(râ¿)
Î£(i=0 to âˆ) râ± = 1/(1-r)    when |r| < 1           â†’ O(1)
```

### **Power Series**
```
Î£(i=1 to n) iÂ² = n(n+1)(2n+1)/6                     â†’ O(nÂ³)
Î£(i=1 to n) iÂ³ = [n(n+1)/2]Â² = (Î£i)Â²                â†’ O(nâ´)
Î£(i=1 to n) iâ´ = n(n+1)(2n+1)(3nÂ²+3n-1)/30         â†’ O(nâµ)
Î£(i=1 to n) iáµ â‰ˆ náµâºÂ¹/(k+1)                         â†’ O(náµâºÂ¹)
```

### **Harmonic & Logarithmic Series**
```
Harmonic Series:
Î£(i=1 to n) 1/i â‰ˆ ln(n) + Î³     (Î³ â‰ˆ 0.5772)       â†’ O(log n)
Î£(i=1 to n) 1/iÂ² = Ï€Â²/6 â‰ˆ 1.645  (converges)       â†’ O(1)

Logarithmic Series:
Î£(i=1 to n) log i = log(n!) â‰ˆ n log n - n           â†’ O(n log n)
Î£(i=1 to n) i log i â‰ˆ nÂ² log n / 2                  â†’ O(nÂ² log n)
Î£(i=1 to n) log i / i â‰ˆ (log n)Â²/2                  â†’ O(logÂ² n)
```

### **Binomial Series**
```
Binomial Theorem: (a+b)â¿ = Î£(k=0 to n) C(n,k) Ã— aâ¿â»áµ Ã— báµ

Sum of Binomial Coefficients:
Î£(k=0 to n) C(n,k) = 2â¿                             â†’ O(2â¿)
Î£(k=0 to n) kÃ—C(n,k) = nÃ—2â¿â»Â¹                       â†’ O(nÃ—2â¿)
Î£(k=0 to n) C(n,k)Â² = C(2n,n)                       â†’ O(4â¿/âˆšn)
```

---

## ğŸ§® **Essential Mathematical Series**

### **Arithmetic Series**
```
Î£(i=1 to n) 1 = n                                    â†’ O(n)
Î£(i=1 to n) i = 1 + 2 + ... + n = n(n+1)/2         â†’ O(nÂ²)
Î£(i=1 to n) iÂ² = 1Â² + 2Â² + ... + nÂ² = n(n+1)(2n+1)/6 â†’ O(nÂ³)
Î£(i=1 to n) iÂ³ = [n(n+1)/2]Â²                        â†’ O(nâ´)
```

### **Geometric Series**
```
Î£(i=0 to n) râ± = (râ¿âºÂ¹ - 1)/(r - 1)    where r > 1
Î£(i=0 to n) 2â± = 2â° + 2Â¹ + ... + 2â¿ = 2â¿âºÂ¹ - 1      â†’ O(2â¿)
Î£(i=0 to n) 3â± = (3â¿âºÂ¹ - 1)/2                      â†’ O(3â¿)
```

### **Harmonic Series**
```
Î£(i=1 to n) 1/i = 1 + 1/2 + 1/3 + ... + 1/n â‰ˆ ln(n) â†’ O(log n)
```

### **Logarithmic Series**
```
Î£(i=1 to n) log i â‰ˆ n log n                         â†’ O(n log n)
log(n!) = log(1Ã—2Ã—...Ã—n) = Î£ log i â‰ˆ n log n        â†’ O(n log n)
```

---

## ğŸ”„ **Recurrence Relations & Master Theorem**

### **Master Theorem Formula**
```
T(n) = aT(n/b) + f(n)

Where:
- a = number of recursive calls
- b = factor by which problem size reduces
- f(n) = work done outside recursion
```

### **Master Theorem Cases**
```
Case 1: f(n) = O(ná¶œ) where c < log_b(a)
        â†’ T(n) = O(n^(log_b(a)))

Case 2: f(n) = O(ná¶œ log^k(n)) where c = log_b(a)
        â†’ T(n) = O(ná¶œ log^(k+1)(n))

Case 3: f(n) = O(ná¶œ) where c > log_b(a)
        â†’ T(n) = O(f(n))
```

### **Common Recurrence Patterns**
```
T(n) = T(n/2) + O(1)           â†’ O(log n)     [Binary Search]
T(n) = 2T(n/2) + O(1)          â†’ O(n)         [Tree Traversal]
T(n) = 2T(n/2) + O(n)          â†’ O(n log n)   [Merge Sort]
T(n) = T(n-1) + O(1)           â†’ O(n)         [Linear Recursion]
T(n) = T(n-1) + O(n)           â†’ O(nÂ²)        [Selection Sort]
T(n) = 2T(n-1) + O(1)          â†’ O(2â¿)        [Fibonacci]
T(n) = nT(n-1) + O(1)          â†’ O(n!)        [Permutations]
```

---

## ğŸ“Š **Loop Analysis Formulas**

### **Single Loop Patterns**
```
for(i=0; i<n; i++)             â†’ Î£(i=0 to n-1) 1 = n           â†’ O(n)
for(i=1; i<=n; i++)            â†’ Î£(i=1 to n) 1 = n             â†’ O(n)
for(i=0; i<n; i+=2)            â†’ Î£(i=0,2,4... to n) 1 = n/2    â†’ O(n)
```

### **Logarithmic Loop Patterns**
```
for(i=1; i<n; i*=2)            â†’ iterations = âŒŠlogâ‚‚(n)âŒ‹        â†’ O(log n)
for(i=n; i>1; i/=2)            â†’ iterations = âŒŠlogâ‚‚(n)âŒ‹        â†’ O(log n)
for(i=1; i<n; i*=k)            â†’ iterations = âŒŠlog_k(n)âŒ‹       â†’ O(log n)
```

### **Nested Loop Formulas**
```
for(i=0; i<n; i++)
  for(j=0; j<n; j++)           â†’ Î£(i=0 to n-1)Î£(j=0 to n-1) 1 = nÂ² â†’ O(nÂ²)

for(i=0; i<n; i++)
  for(j=0; j<=i; j++)          â†’ Î£(i=0 to n-1)Î£(j=0 to i) 1 = n(n+1)/2 â†’ O(nÂ²)

for(i=0; i<n; i++)
  for(j=i; j<n; j++)           â†’ Î£(i=0 to n-1)(n-i) = n(n+1)/2 â†’ O(nÂ²)
```

### **Complex Nested Patterns**
```
for(i=0; i<n; i++)
  for(j=0; j<n; j++)
    for(k=0; k<n; k++)         â†’ nÂ³                             â†’ O(nÂ³)

for(i=0; i<n; i++)
  for(j=0; j<i; j++)
    for(k=0; k<j; k++)         â†’ Î£(i=0 to n)Î£(j=0 to i)j = n(n-1)(n-2)/6 â†’ O(nÂ³)
```

---

## âš¡ **Advanced Mathematical Operations & Laws**

### **Multiplication & Addition Laws for Series**
```
Distributive Law: 
Î£(i=1 to n) [aÃ—f(i) + bÃ—g(i)] = aÃ—Î£f(i) + bÃ—Î£g(i)

Product of Sums:
[Î£(i=1 to n) a_i] Ã— [Î£(j=1 to m) b_j] = Î£(i=1 to n)Î£(j=1 to m) a_iÃ—b_j

Nested Sum Multiplication:
Î£(i=1 to n) i Ã— Î£(j=1 to m) j = [n(n+1)/2] Ã— [m(m+1)/2] â†’ O(nÂ²mÂ²)

Series Convolution:
Î£(k=0 to n) a_k Ã— b_(n-k)                               â†’ O(n) per term
```

### **Advanced Series Identities**
```
Double Summation Rules:
Î£(i=1 to n) Î£(j=1 to i) 1 = Î£(i=1 to n) i = n(n+1)/2   â†’ O(nÂ²)
Î£(i=1 to n) Î£(j=i to n) 1 = Î£(i=1 to n) (n-i+1) = n(n+1)/2 â†’ O(nÂ²)
Î£(i=1 to n) Î£(j=1 to n) f(i,j) = n Ã— Î£(i=1 to n) f(i)  [if f independent]

Triangle Summations:
Î£(i=0 to n) Î£(j=0 to i) j = Î£(i=0 to n) i(i+1)/2 = n(n+1)(n+2)/6 â†’ O(nÂ³)
Î£(i=1 to n) Î£(j=i to n) Î£(k=j to n) 1 = n(n+1)(n+2)/6  â†’ O(nÂ³)
```

### **Complete Logarithm Mathematics**
```
Basic Properties:
log_a(1) = 0
log_a(a) = 1
log_a(a^x) = x
a^(log_a(x)) = x

Arithmetic Operations:
log_a(xy) = log_a(x) + log_a(y)
log_a(x/y) = log_a(x) - log_a(y)
log_a(x^n) = n Ã— log_a(x)
log_a(â¿âˆšx) = log_a(x)/n

Base Conversion:
log_a(x) = log_b(x) / log_b(a) = ln(x) / ln(a)
log_a(b) Ã— log_b(c) = log_a(c)

Change of Base for Big O:
logâ‚‚(n) = logâ‚â‚€(n) / logâ‚â‚€(2) â‰ˆ 3.32 Ã— logâ‚â‚€(n)
But O(logâ‚‚ n) = O(logâ‚â‚€ n) = O(ln n) = O(log n)

Advanced Logarithm Identities:
log(n!) = Î£(i=1 to n) log(i) â‰ˆ n log n - n + O(log n)  â†’ O(n log n)
log(aâ¿) = n log(a)
log(âˆšn) = log(n)/2 = (1/2) log(n)                      â†’ O(log n)
```

### **Exponential & Power Mathematics**
```
Exponential Properties:
a^m Ã— a^n = a^(m+n)
a^m / a^n = a^(m-n)
(a^m)^n = a^(mn)
(ab)^n = a^n Ã— b^n
a^(-n) = 1/a^n

Power Comparison:
For large n: 2^n < 3^n < n^n
n^k < a^n for any constants k, a>1 (eventually)
n! > n^k for any constant k (eventually)
n^n > n! > a^n > n^k (for large n)

Exponential Series:
e^x = Î£(n=0 to âˆ) x^n/n! = 1 + x + xÂ²/2! + xÂ³/3! + ...
2^n = e^(n ln 2)
a^n = e^(n ln a)
```

### **Factorial & Combinatorial Mathematics**
```
Factorial Properties:
n! = n Ã— (n-1)!
n! = Î“(n+1)    [Gamma function]
0! = 1

Stirling's Approximation:
n! â‰ˆ âˆš(2Ï€n) Ã— (n/e)^n
log(n!) â‰ˆ n log n - n + (1/2)log(2Ï€n)                   â†’ O(n log n)

Combinatorial Identities:
C(n,k) = n!/(k!(n-k)!)
C(n,k) = C(n,n-k)
C(n,k) = C(n-1,k-1) + C(n-1,k)    [Pascal's Identity]
Î£(k=0 to n) C(n,k) = 2^n
Î£(k=0 to n) kÃ—C(n,k) = nÃ—2^(n-1)

Permutation Formulas:
P(n,k) = n!/(n-k)! = nÃ—(n-1)Ã—...Ã—(n-k+1)
P(n,n) = n!
```

### **Exponential Properties**
```
a^m Ã— a^n = a^(m+n)
(a^m)^n = a^(mn)
a^m / a^n = a^(m-n)

Growth rates:
2^n < 3^n < n^n (for large n)
n! grows faster than any exponential a^n
```

### **Factorial Approximations**
```
n! = 1 Ã— 2 Ã— 3 Ã— ... Ã— n
Stirling's Approximation: n! â‰ˆ âˆš(2Ï€n) Ã— (n/e)^n
log(n!) â‰ˆ n log n - n Ã— log e â‰ˆ n log n    â†’ O(n log n)
```

---

## ğŸ¯ **Space Complexity Formulas**

### **Array Space Calculations**
```
1D Array: int arr[n]                       â†’ O(n)
2D Array: int matrix[n][m]                 â†’ O(nm)
3D Array: int cube[n][m][p]                â†’ O(nmp)
Dynamic 2D: vector<vector<int>>(n, vector<int>(m)) â†’ O(nm)
```

### **Recursive Space Formulas**
```
Linear Recursion: factorial(n)              â†’ O(n) [call stack depth]
Binary Recursion: fibonacci(n)              â†’ O(n) [max call stack depth]
Tree Recursion: height h                    â†’ O(h) [space for recursion stack]
```

### **Data Structure Space**
```
Hash Table with n elements                  â†’ O(n)
Binary Tree with n nodes                   â†’ O(n)
Graph with V vertices, E edges              â†’ O(V + E)
Adjacency Matrix for V vertices             â†’ O(VÂ²)
Adjacency List for V vertices, E edges      â†’ O(V + E)
```

---

## ğŸ”¥ **Quick Reference Formulas**

### **Complexity Hierarchy (Growth Rates)**
```
O(1) < O(log log n) < O(log n) < O(âˆšn) < O(n) < O(n log n) 
< O(nÂ²) < O(nÂ³) < O(n^k) < O(2^n) < O(n!) < O(n^n)
```

### **Common Algorithm Complexities**
```
Binary Search:           O(log n)
Linear Search:           O(n)
Bubble Sort:             O(nÂ²)
Merge Sort:              O(n log n)
Quick Sort (avg):        O(n log n)
Quick Sort (worst):      O(nÂ²)
Heap Sort:               O(n log n)
Counting Sort:           O(n + k)
Radix Sort:              O(d Ã— (n + k))
Tree Traversal:          O(n)
Graph BFS/DFS:           O(V + E)
Dijkstra's Algorithm:    O((V + E) log V)
Floyd-Warshall:          O(VÂ³)
```

### **Competitive Programming Specific Formulas**
```
Binary Indexed Tree (Fenwick Tree):
Update: O(log n), Query: O(log n), Space: O(n)

Segment Tree:
Build: O(n), Update: O(log n), Query: O(log n), Space: O(4n)

Trie Operations:
Insert/Search: O(L) where L = string length, Space: O(ALPHABET_SIZE Ã— N Ã— L)

Disjoint Set Union (DSU):
Find/Union: O(Î±(n)) â‰ˆ O(1) amortized, where Î± is inverse Ackermann

Matrix Exponentiation:
A^n calculation: O(kÂ³ log n) where kÃ—k is matrix size

Fast Fourier Transform (FFT):
Polynomial multiplication: O(n log n) instead of O(nÂ²)

Number Theory:
GCD using Euclidean: O(log(min(a,b)))
Extended Euclidean: O(log(min(a,b)))
Modular Exponentiation: O(log n)
Prime Sieve (Sieve of Eratosthenes): O(n log log n)
```

### **Advanced Complexity Patterns in CP**
```
Meet in the Middle: O(2^(n/2)) instead of O(2^n)
Square Root Decomposition: O(âˆšn) per query
Heavy-Light Decomposition: O(logÂ² n) per query on tree paths
Centroid Decomposition: O(log n) levels, O(n log n) preprocessing

Dynamic Programming on Subsets:
dp[mask] iterations: O(2^n)
Sum over all subsets: O(3^n)
    for mask in range(2^n):
        for submask in range(mask):  â†’ O(3^n) total

Inclusion-Exclusion Principle:
|Aâ‚ âˆª Aâ‚‚ âˆª ... âˆª Aâ‚™| = Î£|Aáµ¢| - Î£|Aáµ¢ âˆ© Aâ±¼| + Î£|Aáµ¢ âˆ© Aâ±¼ âˆ© Aâ‚–| - ...
Total subsets to check: 2^n                             â†’ O(2^n)
```

### **Memory & Cache Complexity**
```
Cache-Friendly Complexity:
Sequential Access: O(n/B) cache misses for n elements, block size B
Random Access: O(n) cache misses

Memory Hierarchy Model:
L1 Cache: ~1 cycle, ~32KB
L2 Cache: ~3 cycles, ~256KB  
L3 Cache: ~12 cycles, ~8MB
RAM: ~100 cycles, GBs

Cache-Oblivious Algorithms:
Matrix Multiplication: O(nÂ³/BâˆšM) cache misses
Sorting: O(n/B Ã— log_{M/B}(n/B)) cache misses
where M = cache size, B = block size
```

---

## ğŸ¯ **Probability & Expected Value in Complexity**

### **Randomized Algorithm Analysis**
```
Expected Value: E[X] = Î£ x Ã— P(X = x)
Linearity of Expectation: E[X + Y] = E[X] + E[Y]

Randomized QuickSort:
Expected comparisons: E[C] = 2n ln(n) â‰ˆ 1.39n logâ‚‚(n)  â†’ O(n log n)
Worst case: O(nÂ²), but probability < 1/n!

Skip List:
Expected search/insert/delete: O(log n)
Space: O(n) expected

Hash Table with Chaining:
Expected operations: O(1)
Load factor Î± = n/m, expected chain length = Î±

Birthday Paradox:
Probability of collision in hash table size m after n insertions:
P â‰ˆ 1 - e^(-nÂ²/2m)    [when n << m]
```

### **Amortized Analysis Mathematics**
```
Aggregate Method:
Amortized cost = Total cost of n operations / n

Accounting Method:
Assign amortized cost Ã¢áµ¢ to operation i
Î£Ã¢áµ¢ â‰¥ Î£cáµ¢ (actual costs)

Potential Method:
Amortized cost = Actual cost + Î”(Potential)
Î¦(Dáµ¢) â‰¥ Î¦(Dâ‚€) for all states

Dynamic Array (Vector):
n insertions total cost: O(n), amortized per insert: O(1)
Doubling sequence: 1â†’2â†’4â†’8â†’...â†’n costs: 1+2+4+...+n â‰ˆ 2n â†’ O(1) amortized
```

---

## ğŸš€ **Competition-Ready Quick Formulas**

### **Time Limit Estimations**
```
1 second â‰ˆ 10â¸ operations (rough estimate)
Typical constraints and max complexity:

n â‰¤ 10        â†’ O(n!) â‰ˆ 3,628,800 ops
n â‰¤ 18        â†’ O(2^n) â‰ˆ 262,144 ops
n â‰¤ 20        â†’ O(n Ã— 2^n) â‰ˆ 20,971,520 ops
n â‰¤ 100       â†’ O(nÂ³) â‰ˆ 1,000,000 ops
n â‰¤ 1,000     â†’ O(nÂ²) â‰ˆ 1,000,000 ops
n â‰¤ 100,000   â†’ O(n log n) â‰ˆ 1,600,000 ops
n â‰¤ 1,000,000 â†’ O(n) â‰ˆ 1,000,000 ops

For multiple test cases T:
Total complexity = T Ã— (complexity per test case)
```

### **Space Limit Estimations**
```
Typical memory limits: 256MB, 512MB, 1GB

1 int = 4 bytes
1 long long = 8 bytes  
1 double = 8 bytes
1 char = 1 byte

Array sizing:
int arr[1,000,000] â‰ˆ 4MB
int matrix[1000][1000] â‰ˆ 4MB
int matrix[10000][10000] â‰ˆ 400MB (close to limit!)

For n = 10â¶:
O(n) space â‰ˆ 4-8MB âœ“
O(nÂ²) space â‰ˆ 4TB âœ— (impossible!)
```

### **Mathematical Constants for CP**
```
Ï€ â‰ˆ 3.14159265358979323846
e â‰ˆ 2.71828182845904523536
Ï† (Golden ratio) â‰ˆ 1.61803398874989484820
Î³ (Euler-Mascheroni) â‰ˆ 0.57721566490153286060

Modular Arithmetic:
MOD = 10â¹ + 7 = 1000000007 (common in CP)
MOD = 998244353 (NTT-friendly)
MOD = 10â¹ + 9 = 1000000009

Fast exponentiation: a^b mod m in O(log b)
Fermat's Little Theorem: a^(p-1) â‰¡ 1 (mod p) for prime p
Modular inverse: a^(-1) â‰¡ a^(p-2) (mod p) for prime p
```

---

## ğŸ’¡ **Advanced Mathematical Shortcuts & Tricks**

### **Quick Approximations**
```
For large n:
- âˆšn â‰ˆ n^0.5
- log n â‰ˆ 20-30 for typical programming problems
- n log n â‰ˆ n Ã— 20 for n = 10â¶
- nÂ² becomes problematic when n > 10â´
- 2^n becomes impossible when n > 40
```

### **Practical Size Limits**
```
n â‰¤ 10      â†’ O(n!) = 3,628,800 operations OK
n â‰¤ 20      â†’ O(2^n) = 1,048,576 operations OK  
n â‰¤ 100     â†’ O(nÂ³) = 1,000,000 operations OK
n â‰¤ 1,000   â†’ O(nÂ²) = 1,000,000 operations OK
n â‰¤ 100,000 â†’ O(n log n) â‰ˆ 1,500,000 operations OK
n â‰¤ 10â¶     â†’ O(n) = 1,000,000 operations OK
n â‰¤ 10â¸     â†’ O(log n) â‰ˆ 27 operations OK
```

### **Memory Estimation**
```
1 int = 4 bytes
1 long = 8 bytes
1 pointer = 8 bytes (64-bit system)

Array of n integers â‰ˆ 4n bytes
Matrix nÃ—n integers â‰ˆ 4nÂ² bytes
For n = 10â¶: array needs â‰ˆ 4MB, matrix needs â‰ˆ 4TB (impossible!)
```
