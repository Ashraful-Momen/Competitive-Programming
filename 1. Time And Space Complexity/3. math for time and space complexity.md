# Big O Mathematical Laws & Formulas
## Complete Reference Guide

---

## 📐 **Foundation Laws (মূল নিয়ম)**

### **Law 1: Constant Elimination**
```
O(c × f(n)) = O(f(n))    where c is constant
Examples:
O(5n) = O(n)
O(100) = O(1)
O(3n² + 7) = O(n²)
```

### **Law 2: Dominant Term Rule**
```
O(f(n) + g(n)) = O(max(f(n), g(n)))
Examples:
O(n² + n) = O(n²)
O(n³ + n² + n + 1) = O(n³)
O(2ⁿ + n¹⁰⁰) = O(2ⁿ)
```

### **Law 3: Sequential Operations (Addition)**
```
Sequential: O(f(n)) + O(g(n)) = O(f(n) + g(n))
Examples:
Loop1: O(n) + Loop2: O(m) = O(n + m)
O(n) + O(log n) = O(n)
```

### **Law 4: Nested Operations (Multiplication)**
```
Nested: O(f(n)) × O(g(n)) = O(f(n) × g(n))
Examples:
Outer: O(n) × Inner: O(m) = O(nm)
O(n) × O(log n) = O(n log n)
```

---

## 🧮 **Complete Mathematical Series Collection**

### **Arithmetic Progressions (AP)**
```
General AP: a, a+d, a+2d, ..., a+(n-1)d

Sum of AP: S_n = n/2 × [2a + (n-1)d] = n/2 × (first + last)
Examples:
Σ(i=1 to n) i = n(n+1)/2                            → O(n²)
Σ(i=1 to n) (2i-1) = n²                             → O(n²) [odd numbers]
Σ(i=1 to n) 2i = n(n+1)                             → O(n²) [even numbers]
Σ(i=a to b) i = (b-a+1)(a+b)/2                      → O((b-a)²)
```

### **Geometric Progressions (GP)**
```
General GP: a, ar, ar², ..., ar^(n-1)

Sum of GP: S_n = a(r^n - 1)/(r - 1)    when r ≠ 1
          S_n = na                      when r = 1

Examples:
Σ(i=0 to n) 2ⁱ = 2ⁿ⁺¹ - 1                          → O(2ⁿ)
Σ(i=0 to n) 3ⁱ = (3ⁿ⁺¹ - 1)/2                      → O(3ⁿ)
Σ(i=0 to n) rⁱ = (rⁿ⁺¹ - 1)/(r-1)                  → O(rⁿ)
Σ(i=0 to ∞) rⁱ = 1/(1-r)    when |r| < 1           → O(1)
```

### **Power Series**
```
Σ(i=1 to n) i² = n(n+1)(2n+1)/6                     → O(n³)
Σ(i=1 to n) i³ = [n(n+1)/2]² = (Σi)²                → O(n⁴)
Σ(i=1 to n) i⁴ = n(n+1)(2n+1)(3n²+3n-1)/30         → O(n⁵)
Σ(i=1 to n) iᵏ ≈ nᵏ⁺¹/(k+1)                         → O(nᵏ⁺¹)
```

### **Harmonic & Logarithmic Series**
```
Harmonic Series:
Σ(i=1 to n) 1/i ≈ ln(n) + γ     (γ ≈ 0.5772)       → O(log n)
Σ(i=1 to n) 1/i² = π²/6 ≈ 1.645  (converges)       → O(1)

Logarithmic Series:
Σ(i=1 to n) log i = log(n!) ≈ n log n - n           → O(n log n)
Σ(i=1 to n) i log i ≈ n² log n / 2                  → O(n² log n)
Σ(i=1 to n) log i / i ≈ (log n)²/2                  → O(log² n)
```

### **Binomial Series**
```
Binomial Theorem: (a+b)ⁿ = Σ(k=0 to n) C(n,k) × aⁿ⁻ᵏ × bᵏ

Sum of Binomial Coefficients:
Σ(k=0 to n) C(n,k) = 2ⁿ                             → O(2ⁿ)
Σ(k=0 to n) k×C(n,k) = n×2ⁿ⁻¹                       → O(n×2ⁿ)
Σ(k=0 to n) C(n,k)² = C(2n,n)                       → O(4ⁿ/√n)
```

---

## 🧮 **Essential Mathematical Series**

### **Arithmetic Series**
```
Σ(i=1 to n) 1 = n                                    → O(n)
Σ(i=1 to n) i = 1 + 2 + ... + n = n(n+1)/2         → O(n²)
Σ(i=1 to n) i² = 1² + 2² + ... + n² = n(n+1)(2n+1)/6 → O(n³)
Σ(i=1 to n) i³ = [n(n+1)/2]²                        → O(n⁴)
```

### **Geometric Series**
```
Σ(i=0 to n) rⁱ = (rⁿ⁺¹ - 1)/(r - 1)    where r > 1
Σ(i=0 to n) 2ⁱ = 2⁰ + 2¹ + ... + 2ⁿ = 2ⁿ⁺¹ - 1      → O(2ⁿ)
Σ(i=0 to n) 3ⁱ = (3ⁿ⁺¹ - 1)/2                      → O(3ⁿ)
```

### **Harmonic Series**
```
Σ(i=1 to n) 1/i = 1 + 1/2 + 1/3 + ... + 1/n ≈ ln(n) → O(log n)
```

### **Logarithmic Series**
```
Σ(i=1 to n) log i ≈ n log n                         → O(n log n)
log(n!) = log(1×2×...×n) = Σ log i ≈ n log n        → O(n log n)
```

---

## 🔄 **Recurrence Relations & Master Theorem**

### **Master Theorem Formula**
```
T(n) = aT(n/b) + f(n)

Where:
- a = number of recursive calls
- b = factor by which problem size reduces
- f(n) = work done outside recursion
```

### **Master Theorem Cases**
```
Case 1: f(n) = O(nᶜ) where c < log_b(a)
        → T(n) = O(n^(log_b(a)))

Case 2: f(n) = O(nᶜ log^k(n)) where c = log_b(a)
        → T(n) = O(nᶜ log^(k+1)(n))

Case 3: f(n) = O(nᶜ) where c > log_b(a)
        → T(n) = O(f(n))
```

### **Common Recurrence Patterns**
```
T(n) = T(n/2) + O(1)           → O(log n)     [Binary Search]
T(n) = 2T(n/2) + O(1)          → O(n)         [Tree Traversal]
T(n) = 2T(n/2) + O(n)          → O(n log n)   [Merge Sort]
T(n) = T(n-1) + O(1)           → O(n)         [Linear Recursion]
T(n) = T(n-1) + O(n)           → O(n²)        [Selection Sort]
T(n) = 2T(n-1) + O(1)          → O(2ⁿ)        [Fibonacci]
T(n) = nT(n-1) + O(1)          → O(n!)        [Permutations]
```

---

## 📊 **Loop Analysis Formulas**

### **Single Loop Patterns**
```
for(i=0; i<n; i++)             → Σ(i=0 to n-1) 1 = n           → O(n)
for(i=1; i<=n; i++)            → Σ(i=1 to n) 1 = n             → O(n)
for(i=0; i<n; i+=2)            → Σ(i=0,2,4... to n) 1 = n/2    → O(n)
```

### **Logarithmic Loop Patterns**
```
for(i=1; i<n; i*=2)            → iterations = ⌊log₂(n)⌋        → O(log n)
for(i=n; i>1; i/=2)            → iterations = ⌊log₂(n)⌋        → O(log n)
for(i=1; i<n; i*=k)            → iterations = ⌊log_k(n)⌋       → O(log n)
```

### **Nested Loop Formulas**
```
for(i=0; i<n; i++)
  for(j=0; j<n; j++)           → Σ(i=0 to n-1)Σ(j=0 to n-1) 1 = n² → O(n²)

for(i=0; i<n; i++)
  for(j=0; j<=i; j++)          → Σ(i=0 to n-1)Σ(j=0 to i) 1 = n(n+1)/2 → O(n²)

for(i=0; i<n; i++)
  for(j=i; j<n; j++)           → Σ(i=0 to n-1)(n-i) = n(n+1)/2 → O(n²)
```

### **Complex Nested Patterns**
```
for(i=0; i<n; i++)
  for(j=0; j<n; j++)
    for(k=0; k<n; k++)         → n³                             → O(n³)

for(i=0; i<n; i++)
  for(j=0; j<i; j++)
    for(k=0; k<j; k++)         → Σ(i=0 to n)Σ(j=0 to i)j = n(n-1)(n-2)/6 → O(n³)
```

---

## ⚡ **Advanced Mathematical Operations & Laws**

### **Multiplication & Addition Laws for Series**
```
Distributive Law: 
Σ(i=1 to n) [a×f(i) + b×g(i)] = a×Σf(i) + b×Σg(i)

Product of Sums:
[Σ(i=1 to n) a_i] × [Σ(j=1 to m) b_j] = Σ(i=1 to n)Σ(j=1 to m) a_i×b_j

Nested Sum Multiplication:
Σ(i=1 to n) i × Σ(j=1 to m) j = [n(n+1)/2] × [m(m+1)/2] → O(n²m²)

Series Convolution:
Σ(k=0 to n) a_k × b_(n-k)                               → O(n) per term
```

### **Advanced Series Identities**
```
Double Summation Rules:
Σ(i=1 to n) Σ(j=1 to i) 1 = Σ(i=1 to n) i = n(n+1)/2   → O(n²)
Σ(i=1 to n) Σ(j=i to n) 1 = Σ(i=1 to n) (n-i+1) = n(n+1)/2 → O(n²)
Σ(i=1 to n) Σ(j=1 to n) f(i,j) = n × Σ(i=1 to n) f(i)  [if f independent]

Triangle Summations:
Σ(i=0 to n) Σ(j=0 to i) j = Σ(i=0 to n) i(i+1)/2 = n(n+1)(n+2)/6 → O(n³)
Σ(i=1 to n) Σ(j=i to n) Σ(k=j to n) 1 = n(n+1)(n+2)/6  → O(n³)
```

### **Complete Logarithm Mathematics**
```
Basic Properties:
log_a(1) = 0
log_a(a) = 1
log_a(a^x) = x
a^(log_a(x)) = x

Arithmetic Operations:
log_a(xy) = log_a(x) + log_a(y)
log_a(x/y) = log_a(x) - log_a(y)
log_a(x^n) = n × log_a(x)
log_a(ⁿ√x) = log_a(x)/n

Base Conversion:
log_a(x) = log_b(x) / log_b(a) = ln(x) / ln(a)
log_a(b) × log_b(c) = log_a(c)

Change of Base for Big O:
log₂(n) = log₁₀(n) / log₁₀(2) ≈ 3.32 × log₁₀(n)
But O(log₂ n) = O(log₁₀ n) = O(ln n) = O(log n)

Advanced Logarithm Identities:
log(n!) = Σ(i=1 to n) log(i) ≈ n log n - n + O(log n)  → O(n log n)
log(aⁿ) = n log(a)
log(√n) = log(n)/2 = (1/2) log(n)                      → O(log n)
```

### **Exponential & Power Mathematics**
```
Exponential Properties:
a^m × a^n = a^(m+n)
a^m / a^n = a^(m-n)
(a^m)^n = a^(mn)
(ab)^n = a^n × b^n
a^(-n) = 1/a^n

Power Comparison:
For large n: 2^n < 3^n < n^n
n^k < a^n for any constants k, a>1 (eventually)
n! > n^k for any constant k (eventually)
n^n > n! > a^n > n^k (for large n)

Exponential Series:
e^x = Σ(n=0 to ∞) x^n/n! = 1 + x + x²/2! + x³/3! + ...
2^n = e^(n ln 2)
a^n = e^(n ln a)
```

### **Factorial & Combinatorial Mathematics**
```
Factorial Properties:
n! = n × (n-1)!
n! = Γ(n+1)    [Gamma function]
0! = 1

Stirling's Approximation:
n! ≈ √(2πn) × (n/e)^n
log(n!) ≈ n log n - n + (1/2)log(2πn)                   → O(n log n)

Combinatorial Identities:
C(n,k) = n!/(k!(n-k)!)
C(n,k) = C(n,n-k)
C(n,k) = C(n-1,k-1) + C(n-1,k)    [Pascal's Identity]
Σ(k=0 to n) C(n,k) = 2^n
Σ(k=0 to n) k×C(n,k) = n×2^(n-1)

Permutation Formulas:
P(n,k) = n!/(n-k)! = n×(n-1)×...×(n-k+1)
P(n,n) = n!
```

### **Exponential Properties**
```
a^m × a^n = a^(m+n)
(a^m)^n = a^(mn)
a^m / a^n = a^(m-n)

Growth rates:
2^n < 3^n < n^n (for large n)
n! grows faster than any exponential a^n
```

### **Factorial Approximations**
```
n! = 1 × 2 × 3 × ... × n
Stirling's Approximation: n! ≈ √(2πn) × (n/e)^n
log(n!) ≈ n log n - n × log e ≈ n log n    → O(n log n)
```

---

## 🎯 **Space Complexity Formulas**

### **Array Space Calculations**
```
1D Array: int arr[n]                       → O(n)
2D Array: int matrix[n][m]                 → O(nm)
3D Array: int cube[n][m][p]                → O(nmp)
Dynamic 2D: vector<vector<int>>(n, vector<int>(m)) → O(nm)
```

### **Recursive Space Formulas**
```
Linear Recursion: factorial(n)              → O(n) [call stack depth]
Binary Recursion: fibonacci(n)              → O(n) [max call stack depth]
Tree Recursion: height h                    → O(h) [space for recursion stack]
```

### **Data Structure Space**
```
Hash Table with n elements                  → O(n)
Binary Tree with n nodes                   → O(n)
Graph with V vertices, E edges              → O(V + E)
Adjacency Matrix for V vertices             → O(V²)
Adjacency List for V vertices, E edges      → O(V + E)
```

---

## 🔥 **Quick Reference Formulas**

### **Complexity Hierarchy (Growth Rates)**
```
O(1) < O(log log n) < O(log n) < O(√n) < O(n) < O(n log n) 
< O(n²) < O(n³) < O(n^k) < O(2^n) < O(n!) < O(n^n)
```

### **Common Algorithm Complexities**
```
Binary Search:           O(log n)
Linear Search:           O(n)
Bubble Sort:             O(n²)
Merge Sort:              O(n log n)
Quick Sort (avg):        O(n log n)
Quick Sort (worst):      O(n²)
Heap Sort:               O(n log n)
Counting Sort:           O(n + k)
Radix Sort:              O(d × (n + k))
Tree Traversal:          O(n)
Graph BFS/DFS:           O(V + E)
Dijkstra's Algorithm:    O((V + E) log V)
Floyd-Warshall:          O(V³)
```

### **Competitive Programming Specific Formulas**
```
Binary Indexed Tree (Fenwick Tree):
Update: O(log n), Query: O(log n), Space: O(n)

Segment Tree:
Build: O(n), Update: O(log n), Query: O(log n), Space: O(4n)

Trie Operations:
Insert/Search: O(L) where L = string length, Space: O(ALPHABET_SIZE × N × L)

Disjoint Set Union (DSU):
Find/Union: O(α(n)) ≈ O(1) amortized, where α is inverse Ackermann

Matrix Exponentiation:
A^n calculation: O(k³ log n) where k×k is matrix size

Fast Fourier Transform (FFT):
Polynomial multiplication: O(n log n) instead of O(n²)

Number Theory:
GCD using Euclidean: O(log(min(a,b)))
Extended Euclidean: O(log(min(a,b)))
Modular Exponentiation: O(log n)
Prime Sieve (Sieve of Eratosthenes): O(n log log n)
```

### **Advanced Complexity Patterns in CP**
```
Meet in the Middle: O(2^(n/2)) instead of O(2^n)
Square Root Decomposition: O(√n) per query
Heavy-Light Decomposition: O(log² n) per query on tree paths
Centroid Decomposition: O(log n) levels, O(n log n) preprocessing

Dynamic Programming on Subsets:
dp[mask] iterations: O(2^n)
Sum over all subsets: O(3^n)
    for mask in range(2^n):
        for submask in range(mask):  → O(3^n) total

Inclusion-Exclusion Principle:
|A₁ ∪ A₂ ∪ ... ∪ Aₙ| = Σ|Aᵢ| - Σ|Aᵢ ∩ Aⱼ| + Σ|Aᵢ ∩ Aⱼ ∩ Aₖ| - ...
Total subsets to check: 2^n                             → O(2^n)
```

### **Memory & Cache Complexity**
```
Cache-Friendly Complexity:
Sequential Access: O(n/B) cache misses for n elements, block size B
Random Access: O(n) cache misses

Memory Hierarchy Model:
L1 Cache: ~1 cycle, ~32KB
L2 Cache: ~3 cycles, ~256KB  
L3 Cache: ~12 cycles, ~8MB
RAM: ~100 cycles, GBs

Cache-Oblivious Algorithms:
Matrix Multiplication: O(n³/B√M) cache misses
Sorting: O(n/B × log_{M/B}(n/B)) cache misses
where M = cache size, B = block size
```

---

## 🎯 **Probability & Expected Value in Complexity**

### **Randomized Algorithm Analysis**
```
Expected Value: E[X] = Σ x × P(X = x)
Linearity of Expectation: E[X + Y] = E[X] + E[Y]

Randomized QuickSort:
Expected comparisons: E[C] = 2n ln(n) ≈ 1.39n log₂(n)  → O(n log n)
Worst case: O(n²), but probability < 1/n!

Skip List:
Expected search/insert/delete: O(log n)
Space: O(n) expected

Hash Table with Chaining:
Expected operations: O(1)
Load factor α = n/m, expected chain length = α

Birthday Paradox:
Probability of collision in hash table size m after n insertions:
P ≈ 1 - e^(-n²/2m)    [when n << m]
```

### **Amortized Analysis Mathematics**
```
Aggregate Method:
Amortized cost = Total cost of n operations / n

Accounting Method:
Assign amortized cost âᵢ to operation i
Σâᵢ ≥ Σcᵢ (actual costs)

Potential Method:
Amortized cost = Actual cost + Δ(Potential)
Φ(Dᵢ) ≥ Φ(D₀) for all states

Dynamic Array (Vector):
n insertions total cost: O(n), amortized per insert: O(1)
Doubling sequence: 1→2→4→8→...→n costs: 1+2+4+...+n ≈ 2n → O(1) amortized
```

---

## 🚀 **Competition-Ready Quick Formulas**

### **Time Limit Estimations**
```
1 second ≈ 10⁸ operations (rough estimate)
Typical constraints and max complexity:

n ≤ 10        → O(n!) ≈ 3,628,800 ops
n ≤ 18        → O(2^n) ≈ 262,144 ops
n ≤ 20        → O(n × 2^n) ≈ 20,971,520 ops
n ≤ 100       → O(n³) ≈ 1,000,000 ops
n ≤ 1,000     → O(n²) ≈ 1,000,000 ops
n ≤ 100,000   → O(n log n) ≈ 1,600,000 ops
n ≤ 1,000,000 → O(n) ≈ 1,000,000 ops

For multiple test cases T:
Total complexity = T × (complexity per test case)
```

### **Space Limit Estimations**
```
Typical memory limits: 256MB, 512MB, 1GB

1 int = 4 bytes
1 long long = 8 bytes  
1 double = 8 bytes
1 char = 1 byte

Array sizing:
int arr[1,000,000] ≈ 4MB
int matrix[1000][1000] ≈ 4MB
int matrix[10000][10000] ≈ 400MB (close to limit!)

For n = 10⁶:
O(n) space ≈ 4-8MB ✓
O(n²) space ≈ 4TB ✗ (impossible!)
```

### **Mathematical Constants for CP**
```
π ≈ 3.14159265358979323846
e ≈ 2.71828182845904523536
φ (Golden ratio) ≈ 1.61803398874989484820
γ (Euler-Mascheroni) ≈ 0.57721566490153286060

Modular Arithmetic:
MOD = 10⁹ + 7 = 1000000007 (common in CP)
MOD = 998244353 (NTT-friendly)
MOD = 10⁹ + 9 = 1000000009

Fast exponentiation: a^b mod m in O(log b)
Fermat's Little Theorem: a^(p-1) ≡ 1 (mod p) for prime p
Modular inverse: a^(-1) ≡ a^(p-2) (mod p) for prime p
```

---

## 💡 **Advanced Mathematical Shortcuts & Tricks**

### **Quick Approximations**
```
For large n:
- √n ≈ n^0.5
- log n ≈ 20-30 for typical programming problems
- n log n ≈ n × 20 for n = 10⁶
- n² becomes problematic when n > 10⁴
- 2^n becomes impossible when n > 40
```

### **Practical Size Limits**
```
n ≤ 10      → O(n!) = 3,628,800 operations OK
n ≤ 20      → O(2^n) = 1,048,576 operations OK  
n ≤ 100     → O(n³) = 1,000,000 operations OK
n ≤ 1,000   → O(n²) = 1,000,000 operations OK
n ≤ 100,000 → O(n log n) ≈ 1,500,000 operations OK
n ≤ 10⁶     → O(n) = 1,000,000 operations OK
n ≤ 10⁸     → O(log n) ≈ 27 operations OK
```

### **Memory Estimation**
```
1 int = 4 bytes
1 long = 8 bytes
1 pointer = 8 bytes (64-bit system)

Array of n integers ≈ 4n bytes
Matrix n×n integers ≈ 4n² bytes
For n = 10⁶: array needs ≈ 4MB, matrix needs ≈ 4TB (impossible!)
```
