# Complete Guide: Time & Space Complexity Analysis

## ðŸŽ¯ Step-by-Step Process to Find Complexity

### **STEP 1: Identify the Input Size**
- Usually denoted as `n` (array size, string length, etc.)
- Sometimes multiple inputs: `n`, `m`, `k`

### **STEP 2: Count Operations/Memory Usage**

---

## ðŸ” TIME COMPLEXITY TRICKS

### **Trick 1: Loop Analysis**

```python
# Single Loop = O(n)
for i in range(n):
    print(i)  # O(1) operation
# Total: O(n)

# Nested Loops = Multiply
for i in range(n):      # O(n)
    for j in range(m):  # O(m)
        print(i, j)     # O(1)
# Total: O(n Ã— m)

# Triple Nested = O(nÂ³)
for i in range(n):
    for j in range(n):
        for k in range(n):
            print(i, j, k)
# Total: O(nÂ³)
```

### **Trick 2: Loop Dependency Analysis**

```python
# Dependent on outer loop variable
for i in range(n):
    for j in range(i):  # j goes from 0 to i-1
        print(i, j)

# Mathematical calculation:
# i=0: 0 iterations
# i=1: 1 iteration  
# i=2: 2 iterations
# ...
# i=n-1: n-1 iterations
# Total = 0+1+2+...+(n-1) = n(n-1)/2 = O(nÂ²)
```

### **Trick 3: Logarithmic Patterns**

```python
# Dividing by 2 each time = O(log n)
i = n
while i > 1:
    print(i)
    i = i // 2  # Key: dividing by constant

# Binary Search Pattern
def binary_search(arr, target):
    left, right = 0, len(arr) - 1
    while left <= right:  # log n iterations
        mid = (left + right) // 2
        if arr[mid] == target:
            return mid
        elif arr[mid] < target:
            left = mid + 1
        else:
            right = mid - 1
    return -1
# Time: O(log n)
```

### **Trick 4: Recursive Complexity**

```python
# Master Theorem: T(n) = aT(n/b) + f(n)
# where a = number of recursive calls
#       b = input size reduction factor
#       f(n) = work done outside recursion

# Example 1: Factorial
def factorial(n):
    if n <= 1:
        return 1
    return n * factorial(n-1)  # 1 call, reduces by 1
# T(n) = T(n-1) + O(1) = O(n)

# Example 2: Binary Tree Traversal
def traverse(node):
    if not node:
        return
    traverse(node.left)   # 1 call
    traverse(node.right)  # 1 call
# T(n) = 2T(n/2) + O(1) = O(n)

# Example 3: Merge Sort
def merge_sort(arr):
    if len(arr) <= 1:
        return arr
    mid = len(arr) // 2
    left = merge_sort(arr[:mid])    # T(n/2)
    right = merge_sort(arr[mid:])   # T(n/2)
    return merge(left, right)       # O(n)
# T(n) = 2T(n/2) + O(n) = O(n log n)
```

---

## ðŸ’¾ SPACE COMPLEXITY TRICKS

### **Trick 1: Variable Counting**

```python
def example1(n):
    a = 5        # O(1)
    b = 10       # O(1)
    c = a + b    # O(1)
    return c
# Space: O(1) - constant variables

def example2(n):
    arr = [0] * n  # O(n) space
    return sum(arr)
# Space: O(n) - array of size n
```

### **Trick 2: Recursive Space (Call Stack)**

```python
def recursive_func(n):
    if n <= 0:
        return 0
    return n + recursive_func(n-1)
# Each call uses stack space
# Maximum depth = n
# Space: O(n) due to call stack
```

### **Trick 3: Auxiliary Data Structures**

```python
def has_duplicates(arr):
    seen = set()  # Extra space
    for num in arr:
        if num in seen:
            return True
        seen.add(num)  # Worst case: all elements unique
    return False
# Space: O(n) for the set
```

---

## ðŸ§® MATHEMATICAL FORMULAS

### **Common Summations:**
- `1 + 2 + 3 + ... + n = n(n+1)/2 = O(nÂ²)`
- `1 + 2 + 4 + 8 + ... + 2â¿ = 2â¿âºÂ¹ - 1 = O(2â¿)`
- `logâ‚‚(n) + logâ‚‚(n-1) + ... + logâ‚‚(1) = O(n log n)`

### **Master Theorem Cases:**
1. If `f(n) = O(n^c)` where `c < log_b(a)`, then `T(n) = O(n^(log_b(a)))`
2. If `f(n) = O(n^c log^k(n))` where `c = log_b(a)`, then `T(n) = O(n^c log^(k+1)(n))`
3. If `f(n) = O(n^c)` where `c > log_b(a)`, then `T(n) = O(f(n))`

---

## ðŸŽ¯ ANALYSIS EXAMPLES

### **Example 1: Bubble Sort**
```python
def bubble_sort(arr):
    n = len(arr)
    for i in range(n):           # n iterations
        for j in range(n-1-i):   # (n-1), (n-2), ..., 1 iterations
            if arr[j] > arr[j+1]:
                arr[j], arr[j+1] = arr[j+1], arr[j]  # O(1)

# Time Analysis:
# Total comparisons = (n-1) + (n-2) + ... + 1 = n(n-1)/2 = O(nÂ²)
# Space Analysis: O(1) - only using constant extra space
```

### **Example 2: Quick Sort**
```python
def quicksort(arr, low, high):
    if low < high:
        pi = partition(arr, low, high)  # O(n)
        quicksort(arr, low, pi-1)       # T(n/2) average
        quicksort(arr, pi+1, high)      # T(n/2) average

# Time Analysis:
# Best/Average: T(n) = 2T(n/2) + O(n) = O(n log n)
# Worst: T(n) = T(n-1) + O(n) = O(nÂ²)
# Space Analysis: O(log n) average (recursion stack)
```

### **Example 3: Matrix Multiplication**
```python
def matrix_multiply(A, B):
    n = len(A)
    C = [[0] * n for _ in range(n)]  # O(nÂ²) space
    
    for i in range(n):      # n iterations
        for j in range(n):  # n iterations  
            for k in range(n):  # n iterations
                C[i][j] += A[i][k] * B[k][j]  # O(1)
    
    return C

# Time: O(nÂ³) - three nested loops
# Space: O(nÂ²) - result matrix
```

---

## ðŸ”§ QUICK IDENTIFICATION RULES

### **Time Complexity Patterns:**
- **One loop:** O(n)
- **Two nested loops:** O(nÂ²)
- **Dividing in half:** O(log n)
- **Tree traversal:** O(n)
- **Sorting:** O(n log n) typically
- **All permutations:** O(n!)
- **All subsets:** O(2â¿)

### **Space Complexity Patterns:**
- **Few variables:** O(1)
- **One array:** O(n)
- **2D array:** O(nÂ²)
- **Recursion depth:** O(depth)
- **Memoization:** O(unique states)

---

## ðŸŽ¯ STEP-BY-STEP ANALYSIS METHOD

1. **Identify input size:** What grows? (usually n)
2. **Find all loops:** Count nesting levels
3. **Check loop bounds:** Constant or dependent on n?
4. **Analyze recursive calls:** How many? How deep?
5. **Count extra space:** Arrays, recursion stack, etc.
6. **Apply mathematical formulas:** Sum series if needed
7. **Take the dominant term:** Drop constants and lower terms

### **Final Rules:**
- **Drop constants:** O(2n) â†’ O(n)
- **Drop lower terms:** O(nÂ² + n) â†’ O(nÂ²)  
- **Worst case matters:** Always consider the worst scenario
