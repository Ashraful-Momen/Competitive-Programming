### **Competitive Programming Applications**

### **Matrix Exponentiation Problems**
```
Fibonacci Sequence:
[F_{n+1}] = [1  1]^n [F_1]
[F_n    ]   [1  0]   [F_0]

Linear Recurrence: a_n = c‚ÇÅa_{n-1} + c‚ÇÇa_{n-2} + ... + c_k a_{n-k}
Companion Matrix Method for O(k¬≥ log n) solution

Graph Problems:
- Count paths of length k: A^k
- Transitive closure: (I + A)^n
- All-pairs shortest paths: repeated matrix multiplication

SOLVED EXAMPLE 1: Fibonacci using Matrix Exponentiation
Find F‚ÇÅ‚ÇÄ using matrix exponentiation where F‚ÇÄ = 0, F‚ÇÅ = 1

Step 1: Set up recurrence matrix
A = [1  1]  (represents F_{n+1} = F_n + F_{n-1})
    [1  0]

Step 2: Calculate A^9 (since F‚ÇÅ‚ÇÄ = F_{9+1})
A¬≤ = [1  1][1  1] = [2  1]
     [1  0][1  0]   [1  1]

A‚Å¥ = (A¬≤)¬≤ = [2  1]¬≤ = [5  3]
             [1  1]     [3  2]

A‚Å∏ = (A‚Å¥)¬≤ = [5  3]¬≤ = [34  21]
             [3  2]     [21  13]

A‚Åπ = A‚Å∏ √ó A = [34  21][1  1] = [55  34]
              [21  13][1  0]   [34  21]

Step 3: Apply to initial conditions
[F‚ÇÅ‚ÇÄ] = A‚Åπ[F‚ÇÅ] = [55  34][1] = [55]
[F‚Çâ ]     [F‚ÇÄ]   [34  21][0]   [34]

Therefore: F‚ÇÅ‚ÇÄ = 55

Verification: F‚ÇÄ=0, F‚ÇÅ=1, F‚ÇÇ=1, F‚ÇÉ=2, F‚ÇÑ=3, F‚ÇÖ=5, F‚ÇÜ=8, F‚Çá=13, F‚Çà=21, F‚Çâ=34, F‚ÇÅ‚ÇÄ=55 ‚úì

SOLVED EXAMPLE 2: Linear Recurrence Relations
Solve a_n = 2a_{n-1} + 3a_{n-2} with a‚ÇÄ = 1, a‚ÇÅ = 2
Find a‚ÇÅ‚ÇÄ

Step 1: Set up companion matrix
[a_n    ] = [2  3][a_{n-1}]
[a### **Singular Value Decomposition (SVD)**
```
A = UŒ£V·µÄ where:
- U(m√óm) = left singular vectors (orthogonal)
- Œ£(m√ón) = diagonal with singular values œÉ·µ¢ ‚â• 0
- V(n√ón) = right singular vectors (orthogonal)

Relationship to Eigenvalues:
- œÉ·µ¢¬≤ = eigenvalues of A·µÄA = eigenvalues of AA·µÄ
- V = eigenvectors of A·µÄA
- U = eigenvectors of AA·µÄ

Properties:
‚úÖ rank(A) = number of non-zero singular values
‚úÖ ||A||‚ÇÇ = œÉ‚ÇÅ (largest singular value)
‚úÖ ||A||_F = ‚àö(Œ£œÉ·µ¢¬≤)
‚úÖ det(A) = Œ†œÉ·µ¢ (for square matrices)

Thin SVD: A(m√ón) = U(m√ór)Œ£(r√ór)V(r√ón)·µÄ where r = rank(A)

SOLVED EXAMPLE 1: SVD of 2√ó2 Matrix
A = [3  1]
    [1  3]

Step 1: Compute A·µÄA
A·µÄA = [3  1][3  1] = [10  6]
      [1  3][1  3]   [6  10]

Step 2: Find eigenvalues of A·µÄA
det(A·µÄA - ŒªI) = det([10-Œª  6  ]) = (10-Œª)¬≤ - 36
                   [6    10-Œª]
= Œª¬≤ - 20Œª + 100 - 36 = Œª¬≤ - 20Œª + 64
= (Œª - 16)(Œª - 4) = 0

Eigenvalues: Œª‚ÇÅ = 16, Œª‚ÇÇ = 4
Singular values: œÉ‚ÇÅ = ‚àö16 = 4, œÉ‚ÇÇ = ‚àö4 = 2# Complete Matrix Mathematics: Zero to Advanced
## Ultimate Cheat Sheet for Competitive Programming & Machine Learning

---

## üìê **Level 0: Matrix Fundamentals**

### **Matrix Definition & Notation**
```
Matrix A (m√ón): m rows, n columns
A = [a·µ¢‚±º] where i ‚àà [1,m], j ‚àà [1,n]

A = [a‚ÇÅ‚ÇÅ  a‚ÇÅ‚ÇÇ  a‚ÇÅ‚ÇÉ]
    [a‚ÇÇ‚ÇÅ  a‚ÇÇ‚ÇÇ  a‚ÇÇ‚ÇÉ]
    [a‚ÇÉ‚ÇÅ  a‚ÇÉ‚ÇÇ  a‚ÇÉ‚ÇÉ]

Special Matrices:
üî∏ Square Matrix: m = n
üî∏ Row Matrix: 1√ón (row vector)
üî∏ Column Matrix: m√ó1 (column vector)
üî∏ Zero Matrix: All elements = 0
üî∏ Identity Matrix I: I·µ¢‚±º = 1 if i=j, 0 otherwise
```

### **Matrix Types & Properties**
```
Diagonal Matrix: a·µ¢‚±º = 0 when i ‚â† j
D = [d‚ÇÅ  0   0 ]
    [0   d‚ÇÇ  0 ]
    [0   0   d‚ÇÉ]

Upper Triangular: a·µ¢‚±º = 0 when i > j
U = [u‚ÇÅ‚ÇÅ  u‚ÇÅ‚ÇÇ  u‚ÇÅ‚ÇÉ]
    [0    u‚ÇÇ‚ÇÇ  u‚ÇÇ‚ÇÉ]
    [0    0    u‚ÇÉ‚ÇÉ]

Lower Triangular: a·µ¢‚±º = 0 when i < j
L = [l‚ÇÅ‚ÇÅ  0    0  ]
    [l‚ÇÇ‚ÇÅ  l‚ÇÇ‚ÇÇ  0  ]
    [l‚ÇÉ‚ÇÅ  l‚ÇÉ‚ÇÇ  l‚ÇÉ‚ÇÉ]

Symmetric Matrix: A = A·µÄ (a·µ¢‚±º = a‚±º·µ¢)
Skew-Symmetric: A = -A·µÄ (a·µ¢‚±º = -a‚±º·µ¢)
Orthogonal Matrix: AA·µÄ = A·µÄA = I
```

---

## ‚ûï **Level 1: Basic Matrix Operations**

### **Matrix Addition & Subtraction**
```
Condition: Same dimensions (m√ón)
(A ¬± B)·µ¢‚±º = a·µ¢‚±º ¬± b·µ¢‚±º

Properties:
‚úÖ A + B = B + A                    [Commutative]
‚úÖ (A + B) + C = A + (B + C)        [Associative]  
‚úÖ A + O = A                        [Identity]
‚úÖ A + (-A) = O                     [Inverse]

SOLVED EXAMPLE 1: Matrix Addition
A = [1  2  3]    B = [4  -1  2]
    [4  5  6]        [7   3  1]

Solution:
A + B = [1+4  2+(-1)  3+2] = [5  1  5]
        [4+7  5+3     6+1]   [11 8  7]

SOLVED EXAMPLE 2: Matrix Subtraction  
A - B = [1-4  2-(-1)  3-2] = [-3  3   1]
        [4-7  5-3     6-1]   [-3  2   5]

Verification: (A + B) + (A - B) = 2A ‚úì
[5  1  5] + [-3  3  1] = [2   4   6] = 2[1  2  3] ‚úì
[11 8  7]   [-3  2  5]   [8  10  12]    [4  5  6]
```

### **Scalar Multiplication**
```
(kA)·µ¢‚±º = k √ó a·µ¢‚±º

Properties:
‚úÖ k(A + B) = kA + kB              [Distributive over addition]
‚úÖ (k + l)A = kA + lA              [Distributive over scalars]
‚úÖ k(lA) = (kl)A                   [Associative]
‚úÖ 1A = A                          [Identity]

SOLVED EXAMPLE 1: Basic Scalar Multiplication
A = [2  -1   3]    k = 4
    [0   5  -2]

Solution:
4A = [4√ó2  4√ó(-1)  4√ó3 ] = [8   -4   12]
     [4√ó0  4√ó5    4√ó(-2)]   [0   20   -8]

SOLVED EXAMPLE 2: Distributive Property Verification
A = [1  2]    B = [3  1]    k = 3, l = 2
    [4  3]        [0  5]

Left side: (k + l)A = (3 + 2)[1  2] = 5[1  2] = [5   10]
                              [4  3]      [4  3]   [20  15]

Right side: kA + lA = 3[1  2] + 2[1  2] = [3  6] + [2  4] = [5   10]
                       [4  3]     [4  3]   [12 9]   [8  6]   [20  15]

Verification: (k + l)A = kA + lA ‚úì
```

### **Matrix Multiplication**
```
Condition: A(m√ón) √ó B(n√óp) ‚Üí C(m√óp)
c·µ¢‚±º = Œ£(k=1 to n) a·µ¢‚Çñ √ó b‚Çñ‚±º

Properties:
‚úÖ (AB)C = A(BC)                   [Associative]
‚úÖ A(B + C) = AB + AC              [Left Distributive]
‚úÖ (A + B)C = AC + BC              [Right Distributive]
‚ùå AB ‚â† BA (generally)             [NOT Commutative]
‚úÖ AI = IA = A                     [Identity]

Time Complexity: O(mnp) for A(m√ón) √ó B(n√óp)

SOLVED EXAMPLE 1: 2√ó2 Matrix Multiplication
A = [1  2]    B = [5  6]
    [3  4]        [7  8]

Solution:
Step 1: Check dimensions: A(2√ó2) √ó B(2√ó2) ‚Üí C(2√ó2) ‚úì

Step 2: Calculate each element:
c‚ÇÅ‚ÇÅ = a‚ÇÅ‚ÇÅb‚ÇÅ‚ÇÅ + a‚ÇÅ‚ÇÇb‚ÇÇ‚ÇÅ = (1)(5) + (2)(7) = 5 + 14 = 19
c‚ÇÅ‚ÇÇ = a‚ÇÅ‚ÇÅb‚ÇÅ‚ÇÇ + a‚ÇÅ‚ÇÇb‚ÇÇ‚ÇÇ = (1)(6) + (2)(8) = 6 + 16 = 22  
c‚ÇÇ‚ÇÅ = a‚ÇÇ‚ÇÅb‚ÇÅ‚ÇÅ + a‚ÇÇ‚ÇÇb‚ÇÇ‚ÇÅ = (3)(5) + (4)(7) = 15 + 28 = 43
c‚ÇÇ‚ÇÇ = a‚ÇÇ‚ÇÅb‚ÇÅ‚ÇÇ + a‚ÇÇ‚ÇÇb‚ÇÇ‚ÇÇ = (3)(6) + (4)(8) = 18 + 32 = 50

AB = [19  22]
     [43  50]

SOLVED EXAMPLE 2: 3√ó2 √ó 2√ó3 Matrix Multiplication
A = [1  2]    B = [5  6  7]
    [3  4]        [8  9  10]
    [5  6]

Solution:
Dimensions: A(3√ó2) √ó B(2√ó3) ‚Üí C(3√ó3) ‚úì

Row 1: [1  2] √ó [5  6  7] = [1√ó5+2√ó8  1√ó6+2√ó9  1√ó7+2√ó10] = [21  24  27]
              [8  9  10]

Row 2: [3  4] √ó [5  6  7] = [3√ó5+4√ó8  3√ó6+4√ó9  3√ó7+4√ó10] = [47  54  61]
              [8  9  10]

Row 3: [5  6] √ó [5  6  7] = [5√ó5+6√ó8  5√ó6+6√ó9  5√ó7+6√ó10] = [73  84  95]
              [8  9  10]

AB = [21  24  27]
     [47  54  61]
     [73  84  95]

SOLVED EXAMPLE 3: Non-Commutative Verification
A = [1  2]    B = [0  1]
    [3  4]        [1  0]

AB = [1√ó0+2√ó1  1√ó1+2√ó0] = [2  1]
     [3√ó0+4√ó1  3√ó1+4√ó0]   [4  3]

BA = [0√ó1+1√ó3  0√ó2+1√ó4] = [3  4]
     [1√ó1+0√ó3  1√ó2+0√ó4]   [1  2]

Conclusion: AB ‚â† BA (matrix multiplication is not commutative)
```

### **Matrix Transpose**
```
(A·µÄ)·µ¢‚±º = a‚±º·µ¢  (flip rows and columns)

Properties:
‚úÖ (A·µÄ)·µÄ = A
‚úÖ (A + B)·µÄ = A·µÄ + B·µÄ
‚úÖ (kA)·µÄ = kA·µÄ
‚úÖ (AB)·µÄ = B·µÄA·µÄ                    [Order reverses!]

SOLVED EXAMPLE 1: Basic Transpose
A = [1  2  3]
    [4  5  6]

Solution:
A·µÄ = [1  4]    (Row 1 ‚Üí Column 1, Row 2 ‚Üí Column 2)
     [2  5]
     [3  6]

Verification: (A·µÄ)·µÄ = A
(A·µÄ)·µÄ = [1  4]·µÄ = [1  2  3] = A ‚úì
        [2  5]     [4  5  6]
        [3  6]

SOLVED EXAMPLE 2: Property Verification (AB)·µÄ = B·µÄA·µÄ
A = [1  2]    B = [5  6]
    [3  4]        [7  8]

Step 1: Calculate AB
AB = [1√ó5+2√ó7  1√ó6+2√ó8] = [19  22]
     [3√ó5+4√ó7  3√ó6+4√ó8]   [43  50]

Step 2: Calculate (AB)·µÄ
(AB)·µÄ = [19  43]
        [22  50]

Step 3: Calculate B·µÄA·µÄ
B·µÄ = [5  7]    A·µÄ = [1  3]
     [6  8]         [2  4]

B·µÄA·µÄ = [5√ó1+7√ó2  5√ó3+7√ó4] = [19  43]
       [6√ó1+8√ó2  6√ó3+8√ó4]   [22  50]

Verification: (AB)·µÄ = B·µÄA·µÄ ‚úì

SOLVED EXAMPLE 3: Symmetric Matrix Check
A = [2  3  1]
    [3  5  4]
    [1  4  6]

A·µÄ = [2  3  1]
     [3  5  4]
     [1  4  6]

Since A = A·µÄ, matrix A is symmetric.
```

---

## üî¢ **Level 2: Determinants & Systems**

### **Determinant Calculation**

#### **2√ó2 Determinant**
```
det(A) = |a  b| = ad - bc
         |c  d|

SOLVED EXAMPLE 1: Basic 2√ó2 Determinant
A = [3  2]
    [1  4]

Solution:
det(A) = (3)(4) - (2)(1) = 12 - 2 = 10

SOLVED EXAMPLE 2: Negative Determinant
A = [2   5]
    [3  -1]

Solution:
det(A) = (2)(-1) - (5)(3) = -2 - 15 = -17

SOLVED EXAMPLE 3: Zero Determinant (Singular Matrix)
A = [2  4]
    [1  2]

Solution:
det(A) = (2)(2) - (4)(1) = 4 - 4 = 0
Note: det(A) = 0 means matrix is singular (non-invertible)
```

#### **3√ó3 Determinant (Cofactor Expansion)**
```
|a‚ÇÅ‚ÇÅ  a‚ÇÅ‚ÇÇ  a‚ÇÅ‚ÇÉ|
|a‚ÇÇ‚ÇÅ  a‚ÇÇ‚ÇÇ  a‚ÇÇ‚ÇÉ| = a‚ÇÅ‚ÇÅ|a‚ÇÇ‚ÇÇ  a‚ÇÇ‚ÇÉ| - a‚ÇÅ‚ÇÇ|a‚ÇÇ‚ÇÅ  a‚ÇÇ‚ÇÉ| + a‚ÇÅ‚ÇÉ|a‚ÇÇ‚ÇÅ  a‚ÇÇ‚ÇÇ|
|a‚ÇÉ‚ÇÅ  a‚ÇÉ‚ÇÇ  a‚ÇÉ‚ÇÉ|      |a‚ÇÉ‚ÇÇ  a‚ÇÉ‚ÇÉ|      |a‚ÇÉ‚ÇÅ  a‚ÇÉ‚ÇÉ|      |a‚ÇÉ‚ÇÅ  a‚ÇÉ‚ÇÇ|

SOLVED EXAMPLE 1: 3√ó3 Determinant using Cofactor Expansion
A = [2  1  3]
    [0  4  1]
    [1  2  2]

Solution (expanding along row 1):
det(A) = 2|4  1| - 1|0  1| + 3|0  4|
          |2  2|     |1  2|     |1  2|

Step 1: Calculate 2√ó2 determinants
|4  1| = (4)(2) - (1)(2) = 8 - 2 = 6
|2  2|

|0  1| = (0)(2) - (1)(1) = 0 - 1 = -1
|1  2|

|0  4| = (0)(2) - (4)(1) = 0 - 4 = -4
|1  2|

Step 2: Combine results
det(A) = 2(6) - 1(-1) + 3(-4) = 12 + 1 - 12 = 1

SOLVED EXAMPLE 2: Using Rule of Sarrus (3√ó3 only)
A = [1  2  3]
    [4  5  6]  
    [7  8  9]

Step 1: Extend matrix with first two columns
1  2  3 | 1  2
4  5  6 | 4  5  
7  8  9 | 7  8

Step 2: Calculate positive diagonals
‚Üò diagonals: (1√ó5√ó9) + (2√ó6√ó7) + (3√ó4√ó8) = 45 + 84 + 96 = 225

Step 3: Calculate negative diagonals  
‚Üô diagonals: (3√ó5√ó7) + (1√ó6√ó8) + (2√ó4√ó9) = 105 + 48 + 72 = 225

Step 4: Final result
det(A) = 225 - 225 = 0

Note: This matrix is singular (determinant = 0)

SOLVED EXAMPLE 3: Expansion along different row/column
A = [2  0  1]
    [3  1  4]
    [1  2  0]

Expanding along column 2 (has most zeros):
det(A) = -0|3  4| + 1|2  1| - 2|2  1|
          |1  0|     |1  0|     |3  4|

= 0 + 1[(2)(0) - (1)(1)] - 2[(2)(4) - (1)(3)]
= 0 + 1(0 - 1) - 2(8 - 3)  
= 0 - 1 - 2(5)
= -1 - 10 = -11
```

#### **n√ón Determinant (General)**
```
Recursive Formula: det(A) = Œ£(j=1 to n) (-1)^(i+j) √ó a·µ¢‚±º √ó M·µ¢‚±º

LU Decomposition Method: det(A) = det(L) √ó det(U) = Œ†(i=1 to n) u·µ¢·µ¢
Time Complexity: O(n¬≥) using LU decomposition
```

### **Determinant Properties**
```
‚úÖ det(AB) = det(A) √ó det(B)
‚úÖ det(A·µÄ) = det(A)
‚úÖ det(kA) = k^n √ó det(A)    [for n√ón matrix]
‚úÖ det(A‚Åª¬π) = 1/det(A)
‚úÖ det(I) = 1
‚úÖ If row/column is all zeros ‚Üí det(A) = 0
‚úÖ Swapping rows ‚Üí det changes sign
‚úÖ Row operations: adding k√órow_i to row_j doesn't change det
```

### **Matrix Inverse**

#### **2√ó2 Inverse**
```
A‚Åª¬π = (1/det(A)) √ó [ d  -b]    where A = [a  b]
                   [-c   a]              [c  d]

SOLVED EXAMPLE 1: Basic 2√ó2 Inverse
A = [3  2]
    [1  4]

Step 1: Calculate determinant
det(A) = (3)(4) - (2)(1) = 12 - 2 = 10

Step 2: Apply inverse formula
A‚Åª¬π = (1/10) √ó [4  -2] = [0.4  -0.2]
              [-1   3]   [-0.1  0.3]

Step 3: Verification (AA‚Åª¬π = I)
AA‚Åª¬π = [3  2][0.4  -0.2] = [3√ó0.4+2√ó(-0.1)  3√ó(-0.2)+2√ó0.3]
       [1  4][-0.1  0.3]   [1√ó0.4+4√ó(-0.1)  1√ó(-0.2)+4√ó0.3]

     = [1.2-0.2  -0.6+0.6] = [1  0] = I ‚úì
       [0.4-0.4  -0.2+1.2]   [0  1]

SOLVED EXAMPLE 2: Fractional Inverse
A = [2  1]
    [3  2]

Step 1: det(A) = (2)(2) - (1)(3) = 4 - 3 = 1

Step 2: A‚Åª¬π = (1/1) √ó [2  -1] = [2  -1]
                      [-3   2]   [-3  2]

Step 3: Verification
AA‚Åª¬π = [2  1][2  -1] = [4-3  -2+2] = [1  0] ‚úì
       [3  2][-3  2]   [6-6  -3+4]   [0  1]

SOLVED EXAMPLE 3: Non-invertible Matrix
A = [2  4]
    [1  2]

Step 1: det(A) = (2)(2) - (4)(1) = 4 - 4 = 0

Conclusion: Since det(A) = 0, matrix A is singular and has NO inverse.
```

#### **n√ón Inverse (Adjugate Method)**
```
A‚Åª¬π = (1/det(A)) √ó adj(A)
where adj(A) = [C·µ¢‚±º]·µÄ and C·µ¢‚±º = (-1)^(i+j) √ó M·µ¢‚±º

SOLVED EXAMPLE: 3√ó3 Inverse using Adjugate Method
A = [2  1  3]
    [0  4  1]
    [1  2  2]

Step 1: Calculate determinant (from previous example)
det(A) = 1

Step 2: Find cofactor matrix
C‚ÇÅ‚ÇÅ = (-1)^(1+1) √ó |4  1| = 1 √ó (8-2) = 6
                    |2  2|

C‚ÇÅ‚ÇÇ = (-1)^(1+2) √ó |0  1| = -1 √ó (0-1) = 1
                    |1  2|

C‚ÇÅ‚ÇÉ = (-1)^(1+3) √ó |0  4| = 1 √ó (0-4) = -4
                    |1  2|

C‚ÇÇ‚ÇÅ = (-1)^(2+1) √ó |1  3| = -1 √ó (2-6) = 4
                    |2  2|

C‚ÇÇ‚ÇÇ = (-1)^(2+2) √ó |2  3| = 1 √ó (4-3) = 1
                    |1  2|

C‚ÇÇ‚ÇÉ = (-1)^(2+3) √ó |2  1| = -1 √ó (4-1) = -3
                    |1  2|

C‚ÇÉ‚ÇÅ = (-1)^(3+1) √ó |1  3| = 1 √ó (1-12) = -11
                    |4  1|

C‚ÇÉ‚ÇÇ = (-1)^(3+2) √ó |2  3| = -1 √ó (2-0) = -2
                    |0  1|

C‚ÇÉ‚ÇÉ = (-1)^(3+3) √ó |2  1| = 1 √ó (8-0) = 8
                    |0  4|

Step 3: Form cofactor matrix and transpose (adjugate)
Cofactor matrix = [6   1  -4]
                  [4   1  -3]
                  [-11 -2  8]

adj(A) = [6   4  -11]
         [1   1  -2]
         [-4 -3   8]

Step 4: Calculate inverse
A‚Åª¬π = (1/1) √ó adj(A) = [6   4  -11]
                       [1   1  -2]
                       [-4 -3   8]

Step 5: Verification (calculate first element of AA‚Åª¬π)
(AA‚Åª¬π)‚ÇÅ‚ÇÅ = [2  1  3][6]   = 2√ó6 + 1√ó1 + 3√ó(-4) = 12 + 1 - 12 = 1 ‚úì
                    [1]
                    [-4]
```

### **Gaussian Elimination & Row Operations**
```
Elementary Row Operations:
1. R·µ¢ ‚Üî R‚±º         [Swap rows]
2. R·µ¢ ‚Üí kR·µ¢       [Multiply row by scalar k ‚â† 0]
3. R·µ¢ ‚Üí R·µ¢ + kR‚±º  [Add k times row j to row i]

Row Echelon Form (REF):
‚úÖ All zero rows at bottom
‚úÖ Leading entry of each row is 1 (pivot)
‚úÖ Pivot position moves right in successive rows

Reduced Row Echelon Form (RREF):
‚úÖ All conditions of REF
‚úÖ Each pivot is the only non-zero entry in its column

Algorithm Complexity: O(n¬≥) for n√ón matrix
```

---

## üßÆ **Level 3: Advanced Matrix Operations**

### **Matrix Rank**
```
Rank(A) = Number of linearly independent rows/columns
        = Number of non-zero rows in REF
        = Dimension of column space

Properties:
‚úÖ rank(A) ‚â§ min(m,n) for m√ón matrix
‚úÖ rank(AB) ‚â§ min(rank(A), rank(B))
‚úÖ rank(A + B) ‚â§ rank(A) + rank(B)
‚úÖ rank(A·µÄ) = rank(A)
‚úÖ rank(A) = rank(A·µÄA) = rank(AA·µÄ)

Full Rank: rank(A) = min(m,n)
Singular Matrix: rank(A) < n for n√ón matrix

SOLVED EXAMPLE 1: Finding Rank using Row Reduction
A = [1  2  3]
    [2  4  6]
    [1  1  2]

Step 1: Apply row operations to get REF
R‚ÇÇ ‚Üí R‚ÇÇ - 2R‚ÇÅ:  [1  2  3]
                [0  0  0]
                [1  1  2]

R‚ÇÉ ‚Üí R‚ÇÉ - R‚ÇÅ:   [1  2  3]
                [0  0  0]
                [0 -1 -1]

R‚ÇÇ ‚Üî R‚ÇÉ:        [1  2  3]
                [0 -1 -1]
                [0  0  0]

R‚ÇÇ ‚Üí -R‚ÇÇ:       [1  2  3]
                [0  1  1]
                [0  0  0]

Step 2: Count non-zero rows
Number of non-zero rows = 2
Therefore, rank(A) = 2

SOLVED EXAMPLE 2: Rank and Linear Independence
A = [1  0  2]
    [0  1  3]
    [2  1  7]

Step 1: Row reduce to REF
R‚ÇÉ ‚Üí R‚ÇÉ - 2R‚ÇÅ:  [1  0  2]
                [0  1  3]
                [0  1  3]

R‚ÇÉ ‚Üí R‚ÇÉ - R‚ÇÇ:   [1  0  2]
                [0  1  3]
                [0  0  0]

Step 2: Analysis
rank(A) = 2 (two non-zero rows)
Since rank(A) = 2 < 3, the third row is linearly dependent on first two rows.
Indeed: Row‚ÇÉ = 2√óRow‚ÇÅ + 1√óRow‚ÇÇ

SOLVED EXAMPLE 3: Full Rank Matrix
A = [1  2]
    [3  4]

Row reduce:
R‚ÇÇ ‚Üí R‚ÇÇ - 3R‚ÇÅ:  [1  2]
                [0 -2]

Both rows are non-zero, so rank(A) = 2 = min(2,2)
Matrix A has full rank and is invertible.
Verification: det(A) = 4 - 6 = -2 ‚â† 0 ‚úì
```

### **Matrix Powers & Exponentiation**
```
Matrix Power: A^k = A √ó A √ó ... √ó A (k times)

Properties:
‚úÖ A^m √ó A^n = A^(m+n)
‚úÖ (A^m)^n = A^(mn)
‚úÖ A^0 = I (identity matrix)
‚úÖ A^(-k) = (A‚Åª¬π)^k

Fast Matrix Exponentiation: O(n¬≥ log k)

SOLVED EXAMPLE 1: Basic Matrix Power
A = [1  1]
    [1  0]

Calculate A¬≤, A¬≥, A‚Å¥:

Step 1: A¬≤ = A √ó A
A¬≤ = [1  1][1  1] = [1√ó1+1√ó1  1√ó1+1√ó0] = [2  1]
     [1  0][1  0]   [1√ó1+0√ó1  1√ó1+0√ó0]   [1  1]

Step 2: A¬≥ = A¬≤ √ó A  
A¬≥ = [2  1][1  1] = [2√ó1+1√ó1  2√ó1+1√ó0] = [3  2]
     [1  1][1  0]   [1√ó1+1√ó1  1√ó1+1√ó0]   [2  1]

Step 3: A‚Å¥ = A¬≥ √ó A
A‚Å¥ = [3  2][1  1] = [3√ó1+2√ó1  3√ó1+2√ó0] = [5  3]
     [2  1][1  0]   [2√ó1+1√ó1  2√ó1+1√ó0]   [3  2]

Note: This is the Fibonacci matrix! A^n gives F_{n+1} and F_n.

SOLVED EXAMPLE 2: Fast Matrix Exponentiation Algorithm
Calculate A^8 using fast exponentiation:

A^8 = (A^4)^2 = [5  3]¬≤ = [5  3][5  3] = [34  21]
                 [3  2]    [3  2][3  2]   [21  13]

Verification using property A^m √ó A^n = A^(m+n):
A^8 = A^4 √ó A^4 ‚úì

SOLVED EXAMPLE 3: Matrix Power for Recurrence Relations
Solve F_n = F_{n-1} + F_{n-2} with F_0 = 0, F_1 = 1

Step 1: Set up matrix equation
[F_{n+1}] = [1  1]^n [F_1] = [1  1]^n [1]
[F_n    ]   [1  0]   [F_0]   [1  0]   [0]

Step 2: Calculate specific terms using A^n
For n = 5: F_5 from A^4 (since we want F_{4+1})
A^4 = [5  3] ‚Üí [F_5] = [5  3][1] = [5]
      [3  2]     [F_4]   [3  2][0]   [3]

Therefore: F_5 = 5, F_4 = 3
Verification: F_5 = F_4 + F_3 = 3 + 2 = 5 ‚úì (F_3 = 2 from A¬≥)
```

### **Matrix Norms**
```
Vector Norms:
||x||‚ÇÅ = Œ£|x·µ¢|                    [L1 norm, Manhattan]
||x||‚ÇÇ = ‚àö(Œ£x·µ¢¬≤)                  [L2 norm, Euclidean]
||x||‚àû = max|x·µ¢|                  [Infinity norm]
||x||‚Çö = (Œ£|x·µ¢|·µñ)^(1/p)           [Lp norm]

Matrix Norms:
||A||‚ÇÅ = max_j Œ£·µ¢|a·µ¢‚±º|            [Maximum column sum]
||A||‚àû = max_i Œ£‚±º|a·µ¢‚±º|            [Maximum row sum]
||A||‚ÇÇ = ‚àö(largest eigenvalue of A·µÄA) [Spectral norm]
||A||_F = ‚àö(Œ£·µ¢‚±º a·µ¢‚±º¬≤)             [Frobenius norm]

Properties:
‚úÖ ||A||‚ÇÇ ‚â§ ‚àö(||A||‚ÇÅ √ó ||A||‚àû)
‚úÖ ||AB||‚ÇÇ ‚â§ ||A||‚ÇÇ √ó ||B||‚ÇÇ
‚úÖ ||A||_F = ‚àö(tr(A·µÄA))
```

---

## üéØ **Level 4: Eigenvalues & Eigenvectors**

### **Eigenvalue Problem**
```
Definition: Av = Œªv where v ‚â† 0
- Œª (lambda) = eigenvalue (scalar)
- v = eigenvector (non-zero vector)

Characteristic Polynomial:
det(A - ŒªI) = 0

For 2√ó2 matrix A = [a  b]:
                   [c  d]
Characteristic polynomial: Œª¬≤ - (a+d)Œª + (ad-bc) = 0
Trace: tr(A) = a + d = sum of eigenvalues
Determinant: det(A) = ad - bc = product of eigenvalues

Eigenvalue Formula (2√ó2):
Œª = (tr(A) ¬± ‚àö(tr(A)¬≤ - 4det(A)))/2

SOLVED EXAMPLE 1: 2√ó2 Eigenvalues and Eigenvectors
A = [3  1]
    [0  2]

Step 1: Find characteristic polynomial
det(A - ŒªI) = det([3-Œª  1 ]) = (3-Œª)(2-Œª) - (1)(0)
                 [0    2-Œª]
= (3-Œª)(2-Œª) = Œª¬≤ - 5Œª + 6

Step 2: Solve for eigenvalues
Œª¬≤ - 5Œª + 6 = 0
(Œª - 2)(Œª - 3) = 0
Therefore: Œª‚ÇÅ = 2, Œª‚ÇÇ = 3

Step 3: Find eigenvectors
For Œª‚ÇÅ = 2:
(A - 2I)v = 0 ‚Üí [1  1][v‚ÇÅ] = [0]
                [0  0][v‚ÇÇ]   [0]
This gives: v‚ÇÅ + v‚ÇÇ = 0 ‚Üí v‚ÇÇ = -v‚ÇÅ
Eigenvector: v‚ÇÅ = [1] (or any scalar multiple)
                  [-1]

For Œª‚ÇÇ = 3:
(A - 3I)v = 0 ‚Üí [0  1][v‚ÇÅ] = [0]
                [0 -1][v‚ÇÇ]   [0]
This gives: v‚ÇÇ = 0
Eigenvector: v‚ÇÇ = [1] (or any scalar multiple)
                  [0]

Step 4: Verification
Av‚ÇÅ = [3  1][1 ] = [2 ] = 2[1 ] = Œª‚ÇÅv‚ÇÅ ‚úì
      [0  2][-1]   [-2]    [-1]

Av‚ÇÇ = [3  1][1] = [3] = 3[1] = Œª‚ÇÇv‚ÇÇ ‚úì
      [0  2][0]   [0]    [0]

SOLVED EXAMPLE 2: Symmetric Matrix Eigenvalues
A = [4  2]
    [2  1]

Step 1: Characteristic polynomial
det(A - ŒªI) = det([4-Œª  2 ]) = (4-Œª)(1-Œª) - 4
                 [2    1-Œª]
= Œª¬≤ - 5Œª + 4 - 4 = Œª¬≤ - 5Œª

Step 2: Solve eigenvalues
Œª¬≤ - 5Œª = Œª(Œª - 5) = 0
Therefore: Œª‚ÇÅ = 0, Œª‚ÇÇ = 5

Step 3: Find eigenvectors
For Œª‚ÇÅ = 0:
Av = 0 ‚Üí [4  2][v‚ÇÅ] = [0]
         [2  1][v‚ÇÇ]   [0]
4v‚ÇÅ + 2v‚ÇÇ = 0 ‚Üí v‚ÇÇ = -2v‚ÇÅ
Eigenvector: v‚ÇÅ = [1 ] (normalized: [1/‚àö5])
                  [-2]              [-2/‚àö5]

For Œª‚ÇÇ = 5:
(A - 5I)v = 0 ‚Üí [-1  2][v‚ÇÅ] = [0]
                [2  -4][v‚ÇÇ]   [0]
-v‚ÇÅ + 2v‚ÇÇ = 0 ‚Üí v‚ÇÅ = 2v‚ÇÇ
Eigenvector: v‚ÇÇ = [2] (normalized: [2/‚àö5])
                  [1]              [1/‚àö5]

Step 4: Verify orthogonality (for symmetric matrix)
v‚ÇÅ·µÄv‚ÇÇ = [1  -2][2] = 2 - 2 = 0 ‚úì
                [1]

SOLVED EXAMPLE 3: 3√ó3 Eigenvalue Problem
A = [1  0  0]
    [0  2  1]
    [0  1  2]

Step 1: Characteristic polynomial
det(A - ŒªI) = det([1-Œª  0    0 ])
                 [0    2-Œª  1 ]
                 [0    1    2-Œª]

= (1-Œª) det([2-Œª  1 ]) = (1-Œª)[(2-Œª)¬≤ - 1]
          [1    2-Œª]
= (1-Œª)(Œª¬≤ - 4Œª + 4 - 1) = (1-Œª)(Œª¬≤ - 4Œª + 3)
= (1-Œª)(Œª-1)(Œª-3) = -(Œª-1)¬≤(Œª-3)

Step 2: Eigenvalues
Œª‚ÇÅ = 1 (multiplicity 2), Œª‚ÇÇ = 3

Step 3: Eigenvectors
For Œª = 1:
(A - I)v = 0 ‚Üí [0  0  0][v‚ÇÅ]   [0]
               [0  1  1][v‚ÇÇ] = [0]
               [0  1  1][v‚ÇÉ]   [0]

From second row: v‚ÇÇ + v‚ÇÉ = 0 ‚Üí v‚ÇÉ = -v‚ÇÇ
v‚ÇÅ is free variable.
Eigenvectors: [1], [0 ]
              [0]  [1 ]
              [0]  [-1]

For Œª = 3:
(A - 3I)v = 0 ‚Üí [-2  0  0][v‚ÇÅ]   [0]
                [0  -1  1][v‚ÇÇ] = [0]
                [0   1 -1][v‚ÇÉ]   [0]

v‚ÇÅ = 0, v‚ÇÇ = v‚ÇÉ
Eigenvector: [0]
             [1]
             [1]
```

### **Eigenvalue Properties**
```
‚úÖ tr(A) = Œ£Œª·µ¢                     [Trace = sum of eigenvalues]
‚úÖ det(A) = Œ†Œª·µ¢                    [Determinant = product of eigenvalues]
‚úÖ Eigenvalues of A^k are Œª·µ¢^k
‚úÖ Eigenvalues of A‚Åª¬π are 1/Œª·µ¢
‚úÖ Eigenvalues of A + cI are Œª·µ¢ + c
‚úÖ Similar matrices have same eigenvalues
‚úÖ Real symmetric matrices have real eigenvalues
‚úÖ Orthogonal matrix eigenvalues have |Œª·µ¢| = 1
```

### **Diagonalization**
```
A = PDP‚Åª¬π where:
- P = matrix of eigenvectors
- D = diagonal matrix of eigenvalues

Conditions for Diagonalization:
‚úÖ A has n linearly independent eigenvectors
‚úÖ A is diagonalizable ‚ü∫ geometric multiplicity = algebraic multiplicity

Power Computation:
A^k = PD^kP‚Åª¬π where D^k = diag(Œª‚ÇÅ^k, Œª‚ÇÇ^k, ..., Œª‚Çô^k)

Symmetric Matrix Diagonalization:
A = QŒõQ·µÄ where Q is orthogonal (Q·µÄQ = I)
```

### **Spectral Decomposition**
```
For symmetric matrix A:
A = Œª‚ÇÅu‚ÇÅu‚ÇÅ·µÄ + Œª‚ÇÇu‚ÇÇu‚ÇÇ·µÄ + ... + Œª‚Çôu‚Çôu‚Çô·µÄ

where Œª·µ¢ are eigenvalues, u·µ¢ are orthonormal eigenvectors

Rayleigh Quotient:
R(x) = (x·µÄAx)/(x·µÄx)
- Œª_min ‚â§ R(x) ‚â§ Œª_max
- R(u·µ¢) = Œª·µ¢ for eigenvector u·µ¢
```

---

## üîÄ **Level 5: Matrix Decompositions**

### **LU Decomposition**
```
A = LU where:
- L = lower triangular with 1's on diagonal
- U = upper triangular

Algorithm (Gaussian Elimination):
1. Forward elimination ‚Üí U
2. Store multipliers ‚Üí L

Complexity: O(n¬≥)

With Partial Pivoting: PA = LU
- P = permutation matrix
- More numerically stable

Applications:
- Solve Ax = b: solve Ly = Pb, then Ux = y
- Compute determinant: det(A) = ¬±det(U) = ¬±‚àèu·µ¢·µ¢
- Matrix inverse: solve AX = I

SOLVED EXAMPLE 1: 3√ó3 LU Decomposition
A = [2  1  3]
    [4  3  1]
    [2  1  4]

Step 1: Forward elimination with multiplier storage
Original: [2  1  3]
          [4  3  1]
          [2  1  4]

Eliminate column 1:
l‚ÇÇ‚ÇÅ = 4/2 = 2, R‚ÇÇ ‚Üí R‚ÇÇ - 2R‚ÇÅ: [2  1  3]
                                [0  1 -5]
                                [2  1  4]

l‚ÇÉ‚ÇÅ = 2/2 = 1, R‚ÇÉ ‚Üí R‚ÇÉ - 1R‚ÇÅ: [2  1  3]
                                [0  1 -5]
                                [0  0  1]

Eliminate column 2:
l‚ÇÉ‚ÇÇ = 0/1 = 0, R‚ÇÉ ‚Üí R‚ÇÉ - 0R‚ÇÇ: [2  1  3]
                                [0  1 -5]
                                [0  0  1]

Step 2: Extract L and U matrices
U = [2  1  3]
    [0  1 -5]
    [0  0  1]

L = [1  0  0]  (1's on diagonal, multipliers below)
    [2  1  0]
    [1  0  1]

Step 3: Verification LU = A
LU = [1  0  0][2  1  3]   [2      1      3    ]
     [2  1  0][0  1 -5] = [4      3      1    ] = A ‚úì
     [1  0  1][0  0  1]   [2      1      4    ]

SOLVED EXAMPLE 2: Solving System using LU
Solve Ax = b where A from above and b = [8, 10, 9]·µÄ

Step 1: Solve Ly = b
[1  0  0][y‚ÇÅ]   [8 ]
[2  1  0][y‚ÇÇ] = [10]
[1  0  1][y‚ÇÉ]   [9 ]

Forward substitution:
y‚ÇÅ = 8
2y‚ÇÅ + y‚ÇÇ = 10 ‚Üí y‚ÇÇ = 10 - 16 = -6
y‚ÇÅ + y‚ÇÉ = 9 ‚Üí y‚ÇÉ = 9 - 8 = 1

So y = [8, -6, 1]·µÄ

Step 2: Solve Ux = y
[2  1  3][x‚ÇÅ]   [8 ]
[0  1 -5][x‚ÇÇ] = [-6]
[0  0  1][x‚ÇÉ]   [1 ]

Back substitution:
x‚ÇÉ = 1
x‚ÇÇ - 5x‚ÇÉ = -6 ‚Üí x‚ÇÇ = -6 + 5 = -1
2x‚ÇÅ + x‚ÇÇ + 3x‚ÇÉ = 8 ‚Üí x‚ÇÅ = (8 + 1 - 3)/2 = 3

Solution: x = [3, -1, 1]·µÄ

Verification: Ax = [2  1  3][3 ]   [6-1+3]   [8 ]
                   [4  3  1][-1] = [12-3+1] = [10] = b ‚úì
                   [2  1  4][1 ]   [6-1+4]   [9 ]
```

### **QR Decomposition**
```
A = QR where:
- Q = orthogonal matrix (Q·µÄQ = I)
- R = upper triangular

Gram-Schmidt Process:
1. q‚ÇÅ = a‚ÇÅ/||a‚ÇÅ||
2. q‚ÇÇ = (a‚ÇÇ - (a‚ÇÇ¬∑q‚ÇÅ)q‚ÇÅ)/||a‚ÇÇ - (a‚ÇÇ¬∑q‚ÇÅ)q‚ÇÅ||
3. Continue for all columns

SOLVED EXAMPLE 1: QR Decomposition using Gram-Schmidt
A = [1  1]
    [1  0]
    [0  1]

Step 1: Extract columns
a‚ÇÅ = [1]    a‚ÇÇ = [1]
     [1]         [0]
     [0]         [1]

Step 2: Apply Gram-Schmidt
||a‚ÇÅ|| = ‚àö(1¬≤ + 1¬≤ + 0¬≤) = ‚àö2
q‚ÇÅ = a‚ÇÅ/||a‚ÇÅ|| = [1/‚àö2]
                  [1/‚àö2]
                  [0   ]

Step 3: Orthogonalize a‚ÇÇ
a‚ÇÇ¬∑q‚ÇÅ = [1  0  1][1/‚àö2] = 1/‚àö2
                  [1/‚àö2]
                  [0   ]

u‚ÇÇ = a‚ÇÇ - (a‚ÇÇ¬∑q‚ÇÅ)q‚ÇÅ = [1] - (1/‚àö2)[1/‚àö2] = [1] - [1/2] = [1/2]
                      [0]          [1/‚àö2]   [0]   [1/2]   [-1/2]
                      [1]          [0   ]   [1]   [0  ]   [1   ]

||u‚ÇÇ|| = ‚àö((1/2)¬≤ + (-1/2)¬≤ + 1¬≤) = ‚àö(1/4 + 1/4 + 1) = ‚àö(3/2) = ‚àö6/2

q‚ÇÇ = u‚ÇÇ/||u‚ÇÇ|| = [1/‚àö6 ]
                  [-1/‚àö6]
                  [2/‚àö6 ]

Step 4: Form Q and R matrices
Q = [1/‚àö2  1/‚àö6 ]
    [1/‚àö2 -1/‚àö6 ]
    [0     2/‚àö6 ]

R = [||a‚ÇÅ||    a‚ÇÇ¬∑q‚ÇÅ  ] = [‚àö2    1/‚àö2]
    [0       ||u‚ÇÇ||  ]   [0     ‚àö6/2]

Step 5: Verification A = QR
QR = [1/‚àö2  1/‚àö6 ][‚àö2    1/‚àö2] = [1  1]
     [1/‚àö2 -1/‚àö6 ][0     ‚àö6/2]   [1  0] = A ‚úì
     [0     2/‚àö6 ]                [0  1]

SOLVED EXAMPLE 2: Solving Least Squares using QR
Solve min||Ax - b||¬≤ where A from above and b = [2, 1, 1]·µÄ

Step 1: Transform to Rx = Q·µÄb
Q·µÄb = [1/‚àö2  1/‚àö2  0   ][2]   [3/‚àö2  ]
      [1/‚àö6 -1/‚àö6  2/‚àö6][1] = [3/‚àö6  ]
                         [1]

Step 2: Solve Rx = Q·µÄb
[‚àö2    1/‚àö2][x‚ÇÅ]   [3/‚àö2]
[0     ‚àö6/2][x‚ÇÇ] = [3/‚àö6]

Back substitution:
x‚ÇÇ = (3/‚àö6)/(‚àö6/2) = 6/6 = 1
x‚ÇÅ = (3/‚àö2 - (1/‚àö2)√ó1)/‚àö2 = 2/2 = 1

Solution: x = [1, 1]·µÄ
```

### **Singular Value Decomposition (SVD)**
```
A = UŒ£V·µÄ where:
- U(m√óm) = left singular vectors (orthogonal)
- Œ£(m√ón) = diagonal with singular values œÉ·µ¢ ‚â• 0
- V(n√ón) = right singular vectors (orthogonal)

Relationship to Eigenvalues:
- œÉ·µ¢¬≤ = eigenvalues of A·µÄA = eigenvalues of AA·µÄ
- V = eigenvectors of A·µÄA
- U = eigenvectors of AA·µÄ

Properties:
‚úÖ rank(A) = number of non-zero singular values
‚úÖ ||A||‚ÇÇ = œÉ‚ÇÅ (largest singular value)
‚úÖ ||A||_F = ‚àö(Œ£œÉ·µ¢¬≤)
‚úÖ det(A) = Œ†œÉ·µ¢ (for square matrices)

Thin SVD: A(m√ón) = U(m√ór)Œ£(r√ór)V(r√ón)·µÄ where r = rank(A)

SOLVED EXAMPLE 1: SVD of 2√ó2 Matrix
A = [3  1]
    [1  3]

Step 1: Compute A·µÄA
A·µÄA = [3  1][3  1] = [10  6]
      [1  3][1  3]   [6  10]

Step 2: Find eigenvalues of A·µÄA
det(A·µÄA - ŒªI) = det([10-Œª  6  ]) = (10-Œª)¬≤ - 36
                   [6    10-Œª]
= Œª¬≤ - 20Œª + 100 - 36 = Œª¬≤ - 20Œª + 64
= (Œª - 16)(Œª - 4) = 0

Eigenvalues: Œª‚ÇÅ = 16, Œª‚ÇÇ = 4
Singular values: œÉ‚ÇÅ = ‚àö16 = 4, œÉ‚ÇÇ = ‚àö4 = 2

Step 3: Find eigenvectors of A·µÄA (V matrix)
For Œª‚ÇÅ = 16:
(A·µÄA - 16I)v = 0 ‚Üí [-6  6][v‚ÇÅ] = [0]
                    [6  -6][v‚ÇÇ]   [0]
v‚ÇÅ = v‚ÇÇ, so v‚ÇÅ = [1/‚àö2] (normalized)
                  [1/‚àö2]

For Œª‚ÇÇ = 4:
(A·µÄA - 4I)v = 0 ‚Üí [6   6][v‚ÇÅ] = [0]
                   [6   6][v‚ÇÇ]   [0]
v‚ÇÅ = -v‚ÇÇ, so v‚ÇÇ = [1/‚àö2 ] (normalized)
                   [-1/‚àö2]

V = [1/‚àö2   1/‚àö2 ]
    [1/‚àö2  -1/‚àö2]

Step 4: Find U matrix using U = AVŒ£‚Åª¬π
u‚ÇÅ = Av‚ÇÅ/œÉ‚ÇÅ = (1/4)[3  1][1/‚àö2] = (1/4)[4/‚àö2] = [1/‚àö2]
                   [1  3][1/‚àö2]        [4/‚àö2]   [1/‚àö2]

u‚ÇÇ = Av‚ÇÇ/œÉ‚ÇÇ = (1/2)[3  1][1/‚àö2 ] = (1/2)[2/‚àö2 ] = [1/‚àö2 ]
                   [1  3][-1/‚àö2]        [-2/‚àö2]   [-1/‚àö2]

U = [1/‚àö2   1/‚àö2 ]
    [1/‚àö2  -1/‚àö2]

Step 5: Form complete SVD
Œ£ = [4  0]
    [0  2]

A = UŒ£V·µÄ = [1/‚àö2   1/‚àö2 ][4  0][1/‚àö2   1/‚àö2 ]
           [1/‚àö2  -1/‚àö2][0  2][1/‚àö2  -1/‚àö2]

Verification: This equals original A = [3  1] ‚úì
                                       [1  3]

SOLVED EXAMPLE 2: Rank-Deficient Matrix SVD
A = [1  2]
    [2  4]
    [1  2]

Step 1: Compute A·µÄA
A·µÄA = [1  2  1][1  2] = [6  12]
      [2  4  2][2  4]   [12 24]
                [1  2]

Step 2: Find eigenvalues
det(A·µÄA - ŒªI) = det([6-Œª   12 ]) = (6-Œª)(24-Œª) - 144
                   [12   24-Œª]
= Œª¬≤ - 30Œª + 144 - 144 = Œª¬≤ - 30Œª = Œª(Œª - 30)

Eigenvalues: Œª‚ÇÅ = 30, Œª‚ÇÇ = 0
Singular values: œÉ‚ÇÅ = ‚àö30, œÉ‚ÇÇ = 0

Since œÉ‚ÇÇ = 0, rank(A) = 1

Step 3: Find V matrix
For Œª‚ÇÅ = 30:
(A·µÄA - 30I)v = 0 ‚Üí [-24  12][v‚ÇÅ] = [0]
                    [12  -6][v‚ÇÇ]   [0]
v‚ÇÅ = v‚ÇÇ/2, so v‚ÇÅ = [1/‚àö5] (normalized)
                    [2/‚àö5]

For Œª‚ÇÇ = 0:
A·µÄAv = 0 ‚Üí [6  12][v‚ÇÅ] = [0]
           [12 24][v‚ÇÇ]   [0]
v‚ÇÅ = -2v‚ÇÇ, so v‚ÇÇ = [2/‚àö5 ] (normalized)
                    [-1/‚àö5]

V = [1/‚àö5   2/‚àö5 ]
    [2/‚àö5  -1/‚àö5]

Step 4: Find U using QR decomposition of AV
This gives rank-1 decomposition: A = œÉ‚ÇÅu‚ÇÅv‚ÇÅ·µÄ

Result shows A has rank 1, confirming linear dependence in rows.
```

### **Cholesky Decomposition**
```
For positive definite matrix A:
A = LL·µÄ where L is lower triangular

Algorithm:
l·µ¢‚±º = (a·µ¢‚±º - Œ£(k=1 to j-1) l·µ¢‚Çñl‚±º‚Çñ)/l‚±º‚±º  for i > j
l‚±º‚±º = ‚àö(a‚±º‚±º - Œ£(k=1 to j-1) l‚±º‚Çñ¬≤)

Complexity: O(n¬≥/3) - faster than LU

Applications:
- Solve positive definite systems efficiently
- Monte Carlo simulations
- Multivariate normal distributions

SOLVED EXAMPLE 1: 3√ó3 Cholesky Decomposition
A = [4  2  1]
    [2  3  0.5]
    [1  0.5  1]

Step 1: Verify positive definiteness
Check if all leading principal minors > 0:
M‚ÇÅ = 4 > 0 ‚úì
M‚ÇÇ = det([4  2]) = 12 - 4 = 8 > 0 ‚úì
         [2  3]
M‚ÇÉ = det(A) = 4(3√ó1 - 0.5√ó0.5) - 2(2√ó1 - 0.5√ó1) + 1(2√ó0.5 - 3√ó1)
    = 4(2.75) - 2(1.5) + 1(-2.5) = 11 - 3 - 2.5 = 5.5 > 0 ‚úì

Matrix is positive definite.

Step 2: Calculate L elements
l‚ÇÅ‚ÇÅ = ‚àöa‚ÇÅ‚ÇÅ = ‚àö4 = 2
l‚ÇÇ‚ÇÅ = a‚ÇÇ‚ÇÅ/l‚ÇÅ‚ÇÅ = 2/2 = 1
l‚ÇÉ‚ÇÅ = a‚ÇÉ‚ÇÅ/l‚ÇÅ‚ÇÅ = 1/2 = 0.5

l‚ÇÇ‚ÇÇ = ‚àö(a‚ÇÇ‚ÇÇ - l‚ÇÇ‚ÇÅ¬≤) = ‚àö(3 - 1¬≤) = ‚àö2
l‚ÇÉ‚ÇÇ = (a‚ÇÉ‚ÇÇ - l‚ÇÉ‚ÇÅl‚ÇÇ‚ÇÅ)/l‚ÇÇ‚ÇÇ = (0.5 - 0.5√ó1)/‚àö2 = 0

l‚ÇÉ‚ÇÉ = ‚àö(a‚ÇÉ‚ÇÉ - l‚ÇÉ‚ÇÅ¬≤ - l‚ÇÉ‚ÇÇ¬≤) = ‚àö(1 - 0.25 - 0) = ‚àö0.75 = ‚àö3/2

Step 3: Form L matrix
L = [2    0     0  ]
    [1   ‚àö2     0  ]
    [0.5  0   ‚àö3/2]

Step 4: Verification A = LL·µÄ
LL·µÄ = [2    0     0  ][2   1   0.5]
      [1   ‚àö2     0  ][0  ‚àö2    0 ]
      [0.5  0   ‚àö3/2][0   0  ‚àö3/2]

= [4   2   1  ]
  [2   3   0.5] = A ‚úì
  [1  0.5  1  ]

SOLVED EXAMPLE 2: Solving System using Cholesky
Solve Ax = b where A from above and b = [7, 5.5, 2]·µÄ

Step 1: Solve Ly = b
[2    0     0  ][y‚ÇÅ]   [7  ]
[1   ‚àö2     0  ][y‚ÇÇ] = [5.5]
[0.5  0   ‚àö3/2][y‚ÇÉ]   [2  ]

Forward substitution:
2y‚ÇÅ = 7 ‚Üí y‚ÇÅ = 3.5
y‚ÇÅ + ‚àö2y‚ÇÇ = 5.5 ‚Üí y‚ÇÇ = (5.5 - 3.5)/‚àö2 = ‚àö2
0.5y‚ÇÅ + (‚àö3/2)y‚ÇÉ = 2 ‚Üí y‚ÇÉ = (2 - 1.75)√ó(2/‚àö3) = ‚àö3/6

Step 2: Solve L·µÄx = y
[2   1   0.5][x‚ÇÅ]   [3.5 ]
[0  ‚àö2    0 ][x‚ÇÇ] = [‚àö2  ]
[0   0  ‚àö3/2][x‚ÇÉ]   [‚àö3/6]

Back substitution:
(‚àö3/2)x‚ÇÉ = ‚àö3/6 ‚Üí x‚ÇÉ = 1/3
‚àö2x‚ÇÇ = ‚àö2 ‚Üí x‚ÇÇ = 1
2x‚ÇÅ + x‚ÇÇ + 0.5x‚ÇÉ = 3.5 ‚Üí x‚ÇÅ = (3.5 - 1 - 1/6)/2 = 1

Solution: x = [1, 1, 1/3]·µÄ

Verification: Ax = [4  2  1][1  ] = [7  ] = b ‚úì
                   [2  3  0.5][1  ]   [5.5]
                   [1  0.5 1][1/3]    [2  ]
```

---

## üöÄ **Level 6: Advanced Applications**

### **Matrix Calculus**
```
Gradient of Scalar Function:
‚àáf(x) = [‚àÇf/‚àÇx‚ÇÅ, ‚àÇf/‚àÇx‚ÇÇ, ..., ‚àÇf/‚àÇx‚Çô]·µÄ

Matrix Derivatives:
‚àÇ(Ax)/‚àÇx = A
‚àÇ(x·µÄAx)/‚àÇx = (A + A·µÄ)x
‚àÇ(x·µÄa)/‚àÇx = a
‚àÇ(a·µÄx)/‚àÇx = a
‚àÇ(||Ax - b||¬≤)/‚àÇx = 2A·µÄ(Ax - b)

Chain Rule for Matrices:
‚àÇf/‚àÇx = (‚àÇf/‚àÇy)(‚àÇy/‚àÇx) where y = g(x)

Jacobian Matrix:
J = [‚àÇf·µ¢/‚àÇx‚±º] for vector function f(x)

Hessian Matrix:
H = [‚àÇ¬≤f/‚àÇx·µ¢‚àÇx‚±º] (second derivatives)

SOLVED EXAMPLE 1: Gradient of Quadratic Form
f(x) = x·µÄAx where A = [2  1] and x = [x‚ÇÅ]
                      [1  3]         [x‚ÇÇ]

Step 1: Expand the quadratic form
f(x) = [x‚ÇÅ  x‚ÇÇ][2  1][x‚ÇÅ] = [x‚ÇÅ  x‚ÇÇ][2x‚ÇÅ + x‚ÇÇ]
                [1  3][x‚ÇÇ]           [x‚ÇÅ + 3x‚ÇÇ]
= x‚ÇÅ(2x‚ÇÅ + x‚ÇÇ) + x‚ÇÇ(x‚ÇÅ + 3x‚ÇÇ)
= 2x‚ÇÅ¬≤ + x‚ÇÅx‚ÇÇ + x‚ÇÅx‚ÇÇ + 3x‚ÇÇ¬≤
= 2x‚ÇÅ¬≤ + 2x‚ÇÅx‚ÇÇ + 3x‚ÇÇ¬≤

Step 2: Calculate partial derivatives
‚àÇf/‚àÇx‚ÇÅ = 4x‚ÇÅ + 2x‚ÇÇ
‚àÇf/‚àÇx‚ÇÇ = 2x‚ÇÅ + 6x‚ÇÇ

Step 3: Form gradient vector
‚àáf(x) = [4x‚ÇÅ + 2x‚ÇÇ] = [4  2][x‚ÇÅ] = (A + A·µÄ)x
        [2x‚ÇÅ + 6x‚ÇÇ]   [2  6][x‚ÇÇ]

Step 4: Verify using formula
A + A·µÄ = [2  1] + [2  1] = [4  2] ‚úì
         [1  3]   [1  3]   [2  6]

SOLVED EXAMPLE 2: Gradient of Least Squares
f(x) = ||Ax - b||¬≤ where A = [1  2], x = [x‚ÇÅ], b = [3]
                              [3  1]      [x‚ÇÇ]      [1]

Step 1: Expand the objective function
Ax - b = [1  2][x‚ÇÅ] - [3] = [x‚ÇÅ + 2x‚ÇÇ - 3]
         [3  1][x‚ÇÇ]   [1]   [3x‚ÇÅ + x‚ÇÇ - 1]

||Ax - b||¬≤ = (x‚ÇÅ + 2x‚ÇÇ - 3)¬≤ + (3x‚ÇÅ + x‚ÇÇ - 1)¬≤

Step 2: Calculate gradient using formula
‚àáf(x) = 2A·µÄ(Ax - b)

A·µÄ = [1  3]
     [2  1]

Step 3: Compute at specific point x = [1, 1]·µÄ
Ax - b = [1  2][1] - [3] = [0 ]
         [3  1][1]   [1]   [3]

‚àáf(x) = 2[1  3][0] = 2[9] = [18]
          [2  1][3]     [3]   [6]

Step 4: Verify by direct differentiation
f(x) = (x‚ÇÅ + 2x‚ÇÇ - 3)¬≤ + (3x‚ÇÅ + x‚ÇÇ - 1)¬≤
‚àÇf/‚àÇx‚ÇÅ = 2(x‚ÇÅ + 2x‚ÇÇ - 3)(1) + 2(3x‚ÇÅ + x‚ÇÇ - 1)(3)
       = 2(0) + 2(3)(3) = 18 ‚úì
‚àÇf/‚àÇx‚ÇÇ = 2(x‚ÇÅ + 2x‚ÇÇ - 3)(2) + 2(3x‚ÇÅ + x‚ÇÇ - 1)(1)
       = 2(0)(2) + 2(3)(1) = 6 ‚úì

SOLVED EXAMPLE 3: Hessian Matrix Calculation
f(x) = x‚ÇÅ¬≤ + 2x‚ÇÅx‚ÇÇ + 3x‚ÇÇ¬≤

Step 1: Calculate first derivatives
‚àÇf/‚àÇx‚ÇÅ = 2x‚ÇÅ + 2x‚ÇÇ
‚àÇf/‚àÇx‚ÇÇ = 2x‚ÇÅ + 6x‚ÇÇ

Step 2: Calculate second derivatives
‚àÇ¬≤f/‚àÇx‚ÇÅ¬≤ = 2
‚àÇ¬≤f/‚àÇx‚ÇÅ‚àÇx‚ÇÇ = 2
‚àÇ¬≤f/‚àÇx‚ÇÇ‚àÇx‚ÇÅ = 2
‚àÇ¬≤f/‚àÇx‚ÇÇ¬≤ = 6

Step 3: Form Hessian matrix
H = [‚àÇ¬≤f/‚àÇx‚ÇÅ¬≤    ‚àÇ¬≤f/‚àÇx‚ÇÅ‚àÇx‚ÇÇ] = [2  2]
    [‚àÇ¬≤f/‚àÇx‚ÇÇ‚àÇx‚ÇÅ  ‚àÇ¬≤f/‚àÇx‚ÇÇ¬≤ ]   [2  6]

Step 4: Check positive definiteness (for convexity)
det(H‚ÇÅ) = 2 > 0 ‚úì
det(H) = 12 - 4 = 8 > 0 ‚úì
Function is convex (has unique minimum).
```

### **Optimization Applications**
```
Least Squares Solution:
minimize ||Ax - b||¬≤
Solution: x* = (A·µÄA)‚Åª¬πA·µÄb (normal equation)
Using SVD: x* = VŒ£‚Åª¬πU·µÄb

Regularized Least Squares (Ridge):
minimize ||Ax - b||¬≤ + Œª||x||¬≤
Solution: x* = (A·µÄA + ŒªI)‚Åª¬πA·µÄb

Principal Component Analysis (PCA):
1. Center data: XÃÉ = X - mean
2. Covariance: C = XÃÉ·µÄXÃÉ/(n-1)
3. Eigendecomposition: C = VŒõV·µÄ
4. Principal components = columns of V

Linear Discriminant Analysis (LDA):
maximize (w·µÄS·µ¶w)/(w·µÄS·µ®w)
where S·µ¶ = between-class scatter, S·µ® = within-class scatter

SOLVED EXAMPLE 1: Least Squares Solution
Solve min||Ax - b||¬≤ where A = [1  1], b = [3]
                                [1  0]      [1]
                                [0  1]      [2]

Step 1: Compute A·µÄA and A·µÄb
A·µÄA = [1  1  0][1  1] = [2  1]
      [1  0  1][1  0]   [1  2]
               [0  1]

A·µÄb = [1  1  0][3] = [4]
      [1  0  1][1]   [5]
               [2]

Step 2: Solve normal equation (A·µÄA)x = A·µÄb
[2  1][x‚ÇÅ] = [4]
[1  2][x‚ÇÇ]   [5]

From first equation: 2x‚ÇÅ + x‚ÇÇ = 4 ‚Üí x‚ÇÇ = 4 - 2x‚ÇÅ
Substitute into second: x‚ÇÅ + 2(4 - 2x‚ÇÅ) = 5
x‚ÇÅ + 8 - 4x‚ÇÅ = 5 ‚Üí -3x‚ÇÅ = -3 ‚Üí x‚ÇÅ = 1
x‚ÇÇ = 4 - 2(1) = 2

Solution: x* = [1, 2]·µÄ

Step 3: Verification
Ax* = [1  1][1] = [3]
      [1  0][2]   [1]
      [0  1]      [2]

Residual: Ax* - b = [3] - [3] = [0] (perfect fit!)
                    [1]   [1]   [0]
                    [2]   [2]   [0]

SOLVED EXAMPLE 2: PCA Implementation
Data matrix X = [1  2] (2 samples, 2 features)
                [3  4]

Step 1: Center the data
mean = [2, 3]·µÄ
XÃÉ = [1  2] - [2  3] = [-1 -1]
    [3  4]   [2  3]   [1   1]

Step 2: Compute covariance matrix
C = XÃÉ·µÄXÃÉ/(n-1) = [-1  1][-1 -1] √ó (1/1) = [2  2]
                 [-1  1][1   1]          [2  2]

Step 3: Find eigenvalues and eigenvectors
det(C - ŒªI) = det([2-Œª  2  ]) = (2-Œª)¬≤ - 4 = Œª¬≤ - 4Œª = Œª(Œª-4)
                 [2    2-Œª]

Eigenvalues: Œª‚ÇÅ = 4, Œª‚ÇÇ = 0

For Œª‚ÇÅ = 4:
(C - 4I)v = 0 ‚Üí [-2  2][v‚ÇÅ] = [0]
                [2  -2][v‚ÇÇ]   [0]
v‚ÇÅ = v‚ÇÇ, so v‚ÇÅ = [1/‚àö2] (first principal component)
                  [1/‚àö2]

For Œª‚ÇÇ = 0:
Cv = 0 ‚Üí [2  2][v‚ÇÅ] = [0]
         [2  2][v‚ÇÇ]   [0]
v‚ÇÅ = -v‚ÇÇ, so v‚ÇÇ = [1/‚àö2 ] (second principal component)
                   [-1/‚àö2]

Step 4: Project data onto first principal component
Projection = XÃÉv‚ÇÅ = [-1 -1][1/‚àö2] = [-2/‚àö2] = [-‚àö2]
                   [1   1][1/‚àö2]   [2/‚àö2 ]   [‚àö2 ]

First PC captures all variance (Œª‚ÇÅ = 4, Œª‚ÇÇ = 0).

SOLVED EXAMPLE 3: Ridge Regression
Solve min||Ax - b||¬≤ + Œª||x||¬≤ with Œª = 0.1
A = [1  2], b = [5], Œª = 0.1
    [2  1]      [4]

Step 1: Form regularized normal equation
(A·µÄA + ŒªI)x = A·µÄb

A·µÄA = [1  2][1  2] = [5  4]
      [2  1][2  1]   [4  5]

A·µÄA + ŒªI = [5  4] + 0.1[1  0] = [5.1  4  ]
           [4  5]      [0  1]   [4    5.1]

A·µÄb = [1  2][5] = [13]
      [2  1][4]   [14]

Step 2: Solve system
[5.1  4  ][x‚ÇÅ] = [13]
[4    5.1][x‚ÇÇ]   [14]

Using elimination:
x‚ÇÅ = (13√ó5.1 - 14√ó4)/(5.1¬≤ - 16) = (66.3 - 56)/(26.01 - 16) = 10.3/10.01 ‚âà 1.03
x‚ÇÇ = (14√ó5.1 - 13√ó4)/(5.1¬≤ - 16) = (71.4 - 52)/(10.01) = 19.4/10.01 ‚âà 1.94

Ridge solution: x* ‚âà [1.03, 1.94]·µÄ

Compare to ordinary least squares: x_ols = [1, 2]·µÄ
Ridge regression shrinks coefficients slightly toward zero.
```

### **Graph Theory Applications**
```
Adjacency Matrix A:
A·µ¢‚±º = 1 if edge (i,j) exists, 0 otherwise

Powers of Adjacency Matrix:
(A^k)·µ¢‚±º = number of walks of length k from i to j

Laplacian Matrix:
L = D - A where D is degree matrix
Properties:
‚úÖ L is positive semidefinite
‚úÖ Smallest eigenvalue is 0
‚úÖ Number of connected components = multiplicity of eigenvalue 0
‚úÖ Second smallest eigenvalue (Fiedler value) measures connectivity

PageRank Algorithm:
P·µ£ = (1-d)/N + d √ó Œ£(P·µ£(T·µ¢)/C(T·µ¢))
Matrix form: œÄ = Œ±G·µÄœÄ + (1-Œ±)e/n
Solve: (I - Œ±G·µÄ)œÄ = (1-Œ±)e/n
```

### **Machine Learning Applications**
```
Neural Network Weight Update:
W^(new) = W^(old) - Œ∑‚àáW(Loss)

Backpropagation:
Œ¥^(l) = ((W^(l+1))·µÄŒ¥^(l+1)) ‚äô œÉ'(z^(l))
‚àáW^(l) = Œ¥^(l+1)(a^(l))·µÄ
‚àáb^(l) = Œ¥^(l+1)

Covariance Matrix:
Cov(X) = E[(X - Œº)(X - Œº)·µÄ]
Sample covariance: S = (1/(n-1))X·µÄX

Gaussian Distribution:
p(x) = (1/‚àö((2œÄ)^k|Œ£|)) exp(-¬Ω(x-Œº)·µÄŒ£‚Åª¬π(x-Œº))

Support Vector Machine:
Kernel Matrix: K(x·µ¢, x‚±º) = œÜ(x·µ¢)·µÄœÜ(x‚±º)
Decision function: f(x) = Œ£Œ±·µ¢y·µ¢K(x·µ¢,x) + b
```

---

## ‚ö° **Computational Complexity & Algorithms**

### **Time Complexities**
```
Operation                    Complexity      Notes
Matrix Addition             O(mn)           Element-wise
Matrix Multiplication       O(mnp)          Standard algorithm
                           O(n^2.376)      Coppersmith-Winograd
                           O(n^2.373)      Current best
Determinant                O(n¬≥)           LU decomposition
Inverse                    O(n¬≥)           Gaussian elimination
Eigenvalues                O(n¬≥)           QR algorithm
SVD                        O(mn¬≤)          m ‚â• n case
LU Decomposition           O(n¬≥)           
QR Decomposition           O(mn¬≤)          Gram-Schmidt
Matrix Power A^k           O(n¬≥ log k)     Fast exponentiation
```

### **Space Complexities**
```
Dense Matrix (n√ón):        O(n¬≤)
Sparse Matrix:             O(nnz)          nnz = non-zeros
Triangular Matrix:         O(n¬≤/2)
Diagonal Matrix:           O(n)
Band Matrix (bandwidth b): O(nb)
```

### **Numerical Stability Tips**
```
‚úÖ Use pivoting in Gaussian elimination
‚úÖ Prefer QR over normal equations for least squares
‚úÖ Use SVD for rank-deficient problems
‚úÖ Check condition number: Œ∫(A) = œÉmax/œÉmin
‚úÖ Avoid computing A‚Åª¬π explicitly; solve Ax = b instead
‚úÖ Use iterative methods for large sparse systems
```

---

## üéØ **Quick Reference Formulas**

### **Essential Identities**
```
(AB)‚Åª¬π = B‚Åª¬πA‚Åª¬π
(AB)·µÄ = B·µÄA·µÄ
det(AB) = det(A)det(B)
tr(AB) = tr(BA)
rank(AB) ‚â§ min(rank(A), rank(B))
||AB||‚ÇÇ ‚â§ ||A||‚ÇÇ||B||‚ÇÇ
(A ‚äó B)‚Åª¬π = A‚Åª¬π ‚äó B‚Åª¬π          [Kronecker product]
```

### **Block Matrix Operations**
```
Block Multiplication:
[A  B][E  F] = [AE+BG  AF+BH]
[C  D][G  H]   [CE+DG  CF+DH]

Block Determinant:
det([A  B]) = det(A)det(D - CA‚Åª¬πB)  [if A invertible]
   ([C  D])

Block Inverse:
[A  B]‚Åª¬π = [A‚Åª¬π+A‚Åª¬πBS‚Åª¬πCA‚Åª¬π  -A‚Åª¬πBS‚Åª¬π]
[C  D]     [-S‚Åª¬πCA‚Åª¬π           S‚Åª¬π    ]
where S = D - CA‚Åª¬πB (Schur complement)
```

### **Special Matrix Properties**
```
Orthogonal: Q·µÄQ = I ‚Üí ||Qx||‚ÇÇ = ||x||‚ÇÇ
Positive Definite: x·µÄAx > 0 ‚àÄx ‚â† 0
Positive Semidefinite: x·µÄAx ‚â• 0 ‚àÄx
Unitary: U*U = I (complex analog of orthogonal)
Normal: AA* = A*A (includes Hermitian, unitary)
Hermitian: A* = A (complex analog of symmetric)
```

---

## üí° **Competitive Programming Applications**

### **Matrix Exponentiation Problems**
```
Fibonacci Sequence:
[F_{n+1}] = [1  1]^n [F_1]
[F_n    ]   [1  0]   [F_0]

Linear Recurrence: a_n = c‚ÇÅa_{n-1} + c‚ÇÇa_{n-2} + ... + c_k a_{n-k}
Companion Matrix Method for O(k¬≥ log n) solution

Graph Problems:
- Count paths of length k: A^k
- Transitive closure: (I + A)^n
- All-pairs shortest paths: repeated matrix multiplication
```

### **DP Optimization with Matrices**
```
DP State Transition: dp[i] = f(dp[i-1], dp[i-2], ...)
Convert to matrix form: [dp[i], dp[i-1], ...] = M √ó [dp[i-1], dp[i-2], ...]
Compute M^n for nth state

Examples:
- Tiling problems
- Linear recurrences  
- Graph coloring with constraints
- State machine problems
```

### **Geometry Applications**
```
2D Transformations:
Rotation: [cos Œ∏  -sin Œ∏]
         [sin Œ∏   cos Œ∏]

Scaling: [sx  0 ]
        [0   sy]

Translation (homogeneous): [1  0  tx]
                          [0  1  ty]
                          [0  0  1 ]

3D Transformations: 4√ó4 matrices for rotation, scaling, translation

Linear Algebra in Computational Geometry:
- Point-in-polygon tests
- Line intersections
- Convex hull algorithms
- Closest pair problems
```

---

## üöÄ **Advanced Topics Summary**

### **Matrix Functions**
```
Matrix Exponential: e^A = Œ£(k=0 to ‚àû) A^k/k!
Matrix Logarithm: log(A) (for matrices near I)
Matrix Square Root: ‚àöA such that (‚àöA)¬≤ = A
Matrix Sine/Cosine: sin(A), cos(A) using power series
```

### **Tensor Operations**
```
Kronecker Product: A ‚äó B
Hadamard Product: A ‚äô B (element-wise)
Vectorization: vec(ABC) = (C^T ‚äó A)vec(B)
Tensor Decomposition: CP, Tucker, tensor SVD
```

### **Random Matrix Theory**
```
Wishart Distribution: W ~ W_p(n, Œ£)
Random Matrix Eigenvalue Distribution
Marchenko-Pastur Law
Semicircle Law for random symmetric matrices
```

This comprehensive matrix mathematics cheat sheet covers everything from basic operations to advanced applications in competitive programming and machine learning. Each concept includes formulas, properties, complexity analysis, and practical applications!
